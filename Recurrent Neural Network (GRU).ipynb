{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Redo replication but use RNN instead of LASSO subset selection followed by linear regression on selected predictors\n",
    "- Add 3m, 6m, 12m moving averages\n",
    "- send 12 months of data to GRU (simplified LSTM)\n",
    "- Use walk-forward cross-validation to tune hyperparameters, i.e. find best network depth, size, regularization, dropout.\n",
    "\n",
    "- After identifying most promising network structure, backtest: \n",
    "\n",
    "1) train GRU each month on historical data up to that month\n",
    "\n",
    "2) use GRU to predict following month\n",
    "\n",
    "3) go long top 6 industries and short bottom 6 industries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import copy\n",
    "from itertools import product\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, lasso_path, lars_path, LassoLarsIC\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.regularizers import l1\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "import ffn\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly as py\n",
    "# print (py.__version__) # requires version >= 1.9.0\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import *\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Games</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>Chems</th>\n",
       "      <th>Txtls</th>\n",
       "      <th>...</th>\n",
       "      <th>Telcm.lead</th>\n",
       "      <th>Servs.lead</th>\n",
       "      <th>BusEq.lead</th>\n",
       "      <th>Paper.lead</th>\n",
       "      <th>Trans.lead</th>\n",
       "      <th>Whlsl.lead</th>\n",
       "      <th>Rtail.lead</th>\n",
       "      <th>Meals.lead</th>\n",
       "      <th>Fin.lead</th>\n",
       "      <th>Other.lead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yyyymm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192708</th>\n",
       "      <td>2.05</td>\n",
       "      <td>-4.26</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5.92</td>\n",
       "      <td>5.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6.32</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.16</td>\n",
       "      <td>4.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>7.40</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192709</th>\n",
       "      <td>5.83</td>\n",
       "      <td>6.80</td>\n",
       "      <td>4.42</td>\n",
       "      <td>3.97</td>\n",
       "      <td>9.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.44</td>\n",
       "      <td>5.76</td>\n",
       "      <td>1.68</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>4.72</td>\n",
       "      <td>-4.91</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-4.84</td>\n",
       "      <td>-22.03</td>\n",
       "      <td>-5.28</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192710</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.38</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>9.40</td>\n",
       "      <td>4.88</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>-2.86</td>\n",
       "      <td>...</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.09</td>\n",
       "      <td>9.17</td>\n",
       "      <td>16.66</td>\n",
       "      <td>3.70</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>11.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192711</th>\n",
       "      <td>6.96</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.37</td>\n",
       "      <td>16.41</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.47</td>\n",
       "      <td>8.83</td>\n",
       "      <td>5.55</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>11.23</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>10.86</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192712</th>\n",
       "      <td>3.31</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3.05</td>\n",
       "      <td>10.09</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>2.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192801</th>\n",
       "      <td>2.29</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>4.91</td>\n",
       "      <td>3.42</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.44</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-8.62</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192802</th>\n",
       "      <td>-3.29</td>\n",
       "      <td>-5.55</td>\n",
       "      <td>-6.30</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-5.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>2.94</td>\n",
       "      <td>10.79</td>\n",
       "      <td>5.49</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.40</td>\n",
       "      <td>3.18</td>\n",
       "      <td>9.28</td>\n",
       "      <td>8.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192803</th>\n",
       "      <td>4.82</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2.05</td>\n",
       "      <td>8.53</td>\n",
       "      <td>4.97</td>\n",
       "      <td>9.70</td>\n",
       "      <td>3.70</td>\n",
       "      <td>10.25</td>\n",
       "      <td>12.87</td>\n",
       "      <td>8.44</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>4.15</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.65</td>\n",
       "      <td>10.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192804</th>\n",
       "      <td>2.47</td>\n",
       "      <td>4.65</td>\n",
       "      <td>-6.17</td>\n",
       "      <td>5.18</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3.37</td>\n",
       "      <td>9.74</td>\n",
       "      <td>2.13</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-4.63</td>\n",
       "      <td>...</td>\n",
       "      <td>6.29</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.56</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>7.63</td>\n",
       "      <td>3.12</td>\n",
       "      <td>13.80</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192805</th>\n",
       "      <td>1.28</td>\n",
       "      <td>5.16</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1.53</td>\n",
       "      <td>17.36</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>8.95</td>\n",
       "      <td>2.66</td>\n",
       "      <td>-6.68</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-5.56</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>-6.05</td>\n",
       "      <td>-4.15</td>\n",
       "      <td>-7.72</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-12.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192806</th>\n",
       "      <td>-4.24</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>-5.36</td>\n",
       "      <td>-11.09</td>\n",
       "      <td>-6.98</td>\n",
       "      <td>-7.44</td>\n",
       "      <td>-3.46</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>-11.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.40</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192807</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-4.02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>14.84</td>\n",
       "      <td>2.69</td>\n",
       "      <td>12.37</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.74</td>\n",
       "      <td>13.37</td>\n",
       "      <td>12.05</td>\n",
       "      <td>4.91</td>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192808</th>\n",
       "      <td>7.53</td>\n",
       "      <td>12.08</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.16</td>\n",
       "      <td>6.16</td>\n",
       "      <td>9.23</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>14.25</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1.65</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>11.87</td>\n",
       "      <td>-4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192809</th>\n",
       "      <td>1.47</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>10.75</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>10.20</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.31</td>\n",
       "      <td>...</td>\n",
       "      <td>2.56</td>\n",
       "      <td>4.81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-5.88</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>17.84</td>\n",
       "      <td>5.69</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192810</th>\n",
       "      <td>-0.88</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.03</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>5.21</td>\n",
       "      <td>7.74</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>4.82</td>\n",
       "      <td>5.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6.30</td>\n",
       "      <td>17.39</td>\n",
       "      <td>7.84</td>\n",
       "      <td>4.72</td>\n",
       "      <td>8.97</td>\n",
       "      <td>11.57</td>\n",
       "      <td>15.14</td>\n",
       "      <td>9.13</td>\n",
       "      <td>9.62</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192811</th>\n",
       "      <td>6.24</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.41</td>\n",
       "      <td>10.02</td>\n",
       "      <td>0.63</td>\n",
       "      <td>16.20</td>\n",
       "      <td>2.18</td>\n",
       "      <td>4.67</td>\n",
       "      <td>12.01</td>\n",
       "      <td>8.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>7.43</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-3.91</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-12.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192812</th>\n",
       "      <td>0.50</td>\n",
       "      <td>-3.90</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>2.27</td>\n",
       "      <td>-5.94</td>\n",
       "      <td>...</td>\n",
       "      <td>13.04</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.41</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192901</th>\n",
       "      <td>3.15</td>\n",
       "      <td>9.12</td>\n",
       "      <td>3.45</td>\n",
       "      <td>9.92</td>\n",
       "      <td>1.18</td>\n",
       "      <td>6.29</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>3.09</td>\n",
       "      <td>22.54</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>10.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>5.43</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192902</th>\n",
       "      <td>-2.03</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-7.28</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>...</td>\n",
       "      <td>3.95</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-3.17</td>\n",
       "      <td>-9.91</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>-3.87</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192903</th>\n",
       "      <td>-5.04</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>-10.17</td>\n",
       "      <td>-7.39</td>\n",
       "      <td>-7.99</td>\n",
       "      <td>-5.66</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>-7.53</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.92</td>\n",
       "      <td>7.77</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.20</td>\n",
       "      <td>10.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-11.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192904</th>\n",
       "      <td>3.32</td>\n",
       "      <td>13.27</td>\n",
       "      <td>-2.77</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.21</td>\n",
       "      <td>-5.36</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-8.70</td>\n",
       "      <td>2.08</td>\n",
       "      <td>-6.98</td>\n",
       "      <td>-9.29</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>-13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192905</th>\n",
       "      <td>-5.62</td>\n",
       "      <td>-11.44</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-10.81</td>\n",
       "      <td>-6.98</td>\n",
       "      <td>-8.28</td>\n",
       "      <td>-7.46</td>\n",
       "      <td>-14.28</td>\n",
       "      <td>...</td>\n",
       "      <td>13.18</td>\n",
       "      <td>18.49</td>\n",
       "      <td>9.47</td>\n",
       "      <td>12.29</td>\n",
       "      <td>5.45</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>8.69</td>\n",
       "      <td>18.59</td>\n",
       "      <td>5.82</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192906</th>\n",
       "      <td>7.48</td>\n",
       "      <td>11.99</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>5.39</td>\n",
       "      <td>10.12</td>\n",
       "      <td>14.19</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>19.46</td>\n",
       "      <td>1.98</td>\n",
       "      <td>...</td>\n",
       "      <td>13.35</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>5.39</td>\n",
       "      <td>6.48</td>\n",
       "      <td>7.99</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.50</td>\n",
       "      <td>8.10</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192907</th>\n",
       "      <td>4.56</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>6.22</td>\n",
       "      <td>-4.32</td>\n",
       "      <td>2.26</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>...</td>\n",
       "      <td>10.58</td>\n",
       "      <td>-4.11</td>\n",
       "      <td>8.58</td>\n",
       "      <td>9.05</td>\n",
       "      <td>7.97</td>\n",
       "      <td>-6.19</td>\n",
       "      <td>7.76</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.73</td>\n",
       "      <td>-3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192908</th>\n",
       "      <td>3.77</td>\n",
       "      <td>9.39</td>\n",
       "      <td>7.89</td>\n",
       "      <td>5.81</td>\n",
       "      <td>1.10</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.69</td>\n",
       "      <td>11.42</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>38.35</td>\n",
       "      <td>9.45</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>-8.10</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>-5.88</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>-6.28</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192909</th>\n",
       "      <td>-2.64</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>-7.97</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>6.44</td>\n",
       "      <td>-4.46</td>\n",
       "      <td>-7.37</td>\n",
       "      <td>-7.14</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>-14.05</td>\n",
       "      <td>-19.39</td>\n",
       "      <td>-15.30</td>\n",
       "      <td>-8.45</td>\n",
       "      <td>-23.66</td>\n",
       "      <td>-24.61</td>\n",
       "      <td>-20.05</td>\n",
       "      <td>-29.86</td>\n",
       "      <td>-33.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192910</th>\n",
       "      <td>-15.03</td>\n",
       "      <td>-26.72</td>\n",
       "      <td>1.86</td>\n",
       "      <td>-17.80</td>\n",
       "      <td>-12.68</td>\n",
       "      <td>-32.92</td>\n",
       "      <td>-9.79</td>\n",
       "      <td>-18.48</td>\n",
       "      <td>-25.13</td>\n",
       "      <td>-21.78</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>-10.35</td>\n",
       "      <td>-22.33</td>\n",
       "      <td>-14.58</td>\n",
       "      <td>-8.22</td>\n",
       "      <td>-7.04</td>\n",
       "      <td>-13.11</td>\n",
       "      <td>-10.65</td>\n",
       "      <td>-14.39</td>\n",
       "      <td>-15.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192911</th>\n",
       "      <td>-9.91</td>\n",
       "      <td>-12.22</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>-18.38</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-15.10</td>\n",
       "      <td>-10.61</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>-16.41</td>\n",
       "      <td>-16.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192912</th>\n",
       "      <td>-0.39</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.35</td>\n",
       "      <td>-9.56</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.98</td>\n",
       "      <td>-6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-48.99</td>\n",
       "      <td>9.29</td>\n",
       "      <td>7.46</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.97</td>\n",
       "      <td>4.32</td>\n",
       "      <td>11.59</td>\n",
       "      <td>9.54</td>\n",
       "      <td>31.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193001</th>\n",
       "      <td>4.91</td>\n",
       "      <td>-8.75</td>\n",
       "      <td>8.42</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>10.18</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.41</td>\n",
       "      <td>8.03</td>\n",
       "      <td>10.36</td>\n",
       "      <td>...</td>\n",
       "      <td>6.76</td>\n",
       "      <td>58.60</td>\n",
       "      <td>7.15</td>\n",
       "      <td>8.02</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>-5.65</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>5.83</td>\n",
       "      <td>-2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201507</th>\n",
       "      <td>4.03</td>\n",
       "      <td>3.51</td>\n",
       "      <td>9.59</td>\n",
       "      <td>6.09</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.66</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.42</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>-5.69</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-4.13</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-6.54</td>\n",
       "      <td>-5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201508</th>\n",
       "      <td>-4.37</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-8.61</td>\n",
       "      <td>-6.94</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>-8.37</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-6.04</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201509</th>\n",
       "      <td>-1.19</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.37</td>\n",
       "      <td>-9.94</td>\n",
       "      <td>-5.32</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-7.28</td>\n",
       "      <td>-8.38</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>8.84</td>\n",
       "      <td>11.26</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10.19</td>\n",
       "      <td>6.48</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201510</th>\n",
       "      <td>5.81</td>\n",
       "      <td>8.06</td>\n",
       "      <td>10.90</td>\n",
       "      <td>14.61</td>\n",
       "      <td>12.21</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7.74</td>\n",
       "      <td>16.62</td>\n",
       "      <td>7.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201511</th>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-5.02</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201512</th>\n",
       "      <td>1.96</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>1.86</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-5.09</td>\n",
       "      <td>-7.95</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-8.68</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-9.63</td>\n",
       "      <td>-3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>4.28</td>\n",
       "      <td>-8.15</td>\n",
       "      <td>-5.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-9.43</td>\n",
       "      <td>-11.10</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.99</td>\n",
       "      <td>6.89</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0.95</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.18</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.36</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>4.69</td>\n",
       "      <td>5.61</td>\n",
       "      <td>5.04</td>\n",
       "      <td>8.61</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>8.33</td>\n",
       "      <td>3.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>-5.46</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-6.30</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>2.06</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-4.96</td>\n",
       "      <td>2.46</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>2.06</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>4.75</td>\n",
       "      <td>5.31</td>\n",
       "      <td>6.87</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.52</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>4.04</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201607</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.15</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.29</td>\n",
       "      <td>8.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201608</th>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4.33</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>2.86</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-3.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.92</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201610</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>4.59</td>\n",
       "      <td>5.59</td>\n",
       "      <td>-10.28</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.21</td>\n",
       "      <td>12.75</td>\n",
       "      <td>9.29</td>\n",
       "      <td>2.99</td>\n",
       "      <td>8.47</td>\n",
       "      <td>12.84</td>\n",
       "      <td>8.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>-4.41</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>3.87</td>\n",
       "      <td>8.15</td>\n",
       "      <td>-4.18</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>4.65</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.34</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>4.43</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.39</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.45</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701</th>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>5.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.79</td>\n",
       "      <td>6.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>3.23</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.35</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201702</th>\n",
       "      <td>1.71</td>\n",
       "      <td>6.13</td>\n",
       "      <td>7.93</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3.81</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201703</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.79</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.94</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201704</th>\n",
       "      <td>0.76</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.24</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.57</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.93</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201705</th>\n",
       "      <td>1.63</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201706</th>\n",
       "      <td>-2.65</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.49</td>\n",
       "      <td>1.93</td>\n",
       "      <td>4.39</td>\n",
       "      <td>...</td>\n",
       "      <td>5.25</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201707</th>\n",
       "      <td>1.52</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201708</th>\n",
       "      <td>-2.77</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-5.79</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.62</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.44</td>\n",
       "      <td>6.20</td>\n",
       "      <td>4.46</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201709</th>\n",
       "      <td>0.43</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.54</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>5.93</td>\n",
       "      <td>7.12</td>\n",
       "      <td>4.28</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.22</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201710</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>2.02</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>3.47</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.41</td>\n",
       "      <td>4.21</td>\n",
       "      <td>6.66</td>\n",
       "      <td>3.37</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.45</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201711</th>\n",
       "      <td>4.15</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>7.94</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>2.73</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4.65</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>...</td>\n",
       "      <td>3.08</td>\n",
       "      <td>9.25</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.56</td>\n",
       "      <td>4.84</td>\n",
       "      <td>11.37</td>\n",
       "      <td>3.12</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1085 rows  150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food   Beer  Smoke  Games  Books  Hshld  Clths   Hlth  Chems  Txtls  \\\n",
       "yyyymm                                                                         \n",
       "192708   2.05  -4.26   3.55   5.92   5.18   0.24   1.28   0.00   1.82   0.19   \n",
       "192709   5.83   6.80   4.42   3.97   9.83   2.32   4.44   5.44   5.76   1.68   \n",
       "192710  -2.71  -1.05  -0.57   0.01   2.38  -2.09   9.40   4.88  -7.71  -2.86   \n",
       "192711   6.96  10.08   6.48   3.37  16.41   2.52   1.85   3.47   8.83   5.55   \n",
       "192712   3.31  12.50   0.81   2.59   3.05  10.09  -0.37  -0.68  -0.45   2.45   \n",
       "192801   2.29   0.37  -2.81  -0.62   4.91   3.42   6.82   2.44  -1.33  -1.35   \n",
       "192802  -3.29  -5.55  -6.30  -1.22  -2.08  -0.34  -2.78  -1.71   0.40  -5.64   \n",
       "192803   4.82  14.18   2.05   8.53   4.97   9.70   3.70  10.25  12.87   8.44   \n",
       "192804   2.47   4.65  -6.17   5.18  21.01   3.37   9.74   2.13  -0.48  -4.63   \n",
       "192805   1.28   5.16  -0.35   1.53  17.36  -2.84  -1.31   8.95   2.66  -6.68   \n",
       "192806  -4.24  -4.52  -4.61  -5.36 -11.09  -6.98  -7.44  -3.46  -3.26 -11.29   \n",
       "192807   0.74   0.38   3.03   1.24   0.81   0.36   0.21   2.07   1.50  -4.02   \n",
       "192808   7.53  12.08   3.47   9.16   6.16   9.23  -0.14  14.25   8.57   1.65   \n",
       "192809   1.47  -0.01  -0.66  10.75  -2.63  10.20  -1.40  -1.41   3.50   3.31   \n",
       "192810  -0.88   3.63   3.03  -1.62   5.21   7.74  -3.96  -0.36   4.82   5.56   \n",
       "192811   6.24   5.32   6.41  10.02   0.63  16.20   2.18   4.67  12.01   8.72   \n",
       "192812   0.50  -3.90  -1.98  -0.72  -0.55  -3.69  -0.44  -0.47   2.27  -5.94   \n",
       "192901   3.15   9.12   3.45   9.92   1.18   6.29  -2.22   3.09  22.54  -1.60   \n",
       "192902  -2.03  -4.42  -5.00   0.80  -1.85  -7.28  -4.44  -0.31  -0.55   1.85   \n",
       "192903  -5.04  -3.24  -4.53 -10.17  -7.39  -7.99  -5.66  -1.84  -3.71  -7.53   \n",
       "192904   3.32  13.27  -2.77   0.31   1.37   0.20   3.26   1.12   3.40   2.38   \n",
       "192905  -5.62 -11.44  -0.65  -8.51  -0.13 -10.81  -6.98  -8.28  -7.46 -14.28   \n",
       "192906   7.48  11.99  -0.65   5.39  10.12  14.19   5.11   4.00  19.46   1.98   \n",
       "192907   4.56   1.28   1.72  -2.52   0.61   6.22  -4.32   2.26   4.79  -4.01   \n",
       "192908   3.77   9.39   7.89   5.81   1.10   3.12   0.57   2.69  11.42  -0.14   \n",
       "192909  -2.64  -2.61  -7.97  -1.99  -2.06   6.44  -4.46  -7.37  -7.14  -3.60   \n",
       "192910 -15.03 -26.72   1.86 -17.80 -12.68 -32.92  -9.79 -18.48 -25.13 -21.78   \n",
       "192911  -9.91 -12.22  -6.57 -18.38  -3.73 -15.10 -10.61  -8.27 -16.41 -16.18   \n",
       "192912  -0.39   1.66   2.35  -9.56  -0.16   0.76   3.33   0.74   5.98  -6.63   \n",
       "193001   4.91  -8.75   8.42  25.00   1.96  10.18   3.54   2.41   8.03  10.36   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "201507   4.03   3.51   9.59   6.09  -2.90   0.71   5.96   3.66  -4.90  -0.72   \n",
       "201508  -4.37  -3.12  -4.06  -7.35  -8.61  -6.94  -3.86  -8.37  -7.15  -3.11   \n",
       "201509  -1.19   2.58   2.37  -9.94  -5.32  -0.53   1.18  -7.28  -8.38  -5.92   \n",
       "201510   5.81   8.06  10.90  14.61  12.21   5.81   0.98   7.74  16.62   7.96   \n",
       "201511   0.11  -0.71  -3.00  -0.41  -1.17  -1.10  -1.08   0.71   1.68  -2.59   \n",
       "201512   1.96   0.30   1.59  -1.70  -6.18   1.86  -4.38   0.39  -4.82  -2.65   \n",
       "201601  -1.67  -0.23   4.28  -8.15  -5.28   0.16   1.52  -9.43 -11.10  -5.33   \n",
       "201602   0.95  -2.34   0.93   4.25  -0.96   0.34   0.81  -1.09   6.79   0.63   \n",
       "201603   4.69   5.61   5.04   8.61   6.88   4.65   2.30   2.90   8.33   3.58   \n",
       "201604   0.63   0.31  -0.25  -6.30   1.82  -0.42  -2.27   3.55   3.77   1.55   \n",
       "201605   2.06  -0.91   0.83   5.42  -0.53  -0.09  -4.96   2.46  -1.42  -1.70   \n",
       "201606   4.75   5.31   6.87  -4.43  -0.34   3.16   1.63   0.11  -1.14  -4.67   \n",
       "201607  -0.51   1.82  -2.79   6.15   7.38   2.58   1.62   6.00   4.29   8.39   \n",
       "201608  -0.52  -0.90  -1.22   0.94   0.29   1.24   1.37  -3.24   2.48   1.03   \n",
       "201609  -2.92   1.63  -2.78   4.62  -3.95   0.00  -6.92   0.35  -1.76  -4.87   \n",
       "201610  -0.33  -1.65   4.59   5.59 -10.28  -2.96  -5.76  -7.45  -1.95  -4.17   \n",
       "201611  -4.41  -5.76  -5.12   3.87   8.15  -4.18   1.80   1.37   7.55   1.58   \n",
       "201612   4.43   3.00   5.39  -3.36   1.98   1.43  -0.44   0.82   0.32  -1.27   \n",
       "201701   0.95  -1.02   5.61   4.84   1.60   2.72  -0.01   2.17   3.79   6.90   \n",
       "201702   1.71   6.13   7.93   0.65  -0.39   4.83   3.81   7.03   3.10  -2.12   \n",
       "201703   0.52   0.89   1.03   5.79  -0.92  -0.36   0.32  -0.19   2.17   1.94   \n",
       "201704   0.76   1.89  -0.14   2.74  -0.83  -0.36  -1.24   1.06   1.28   3.24   \n",
       "201705   1.63   4.28   6.12   2.80  -1.71   1.77  -2.17  -0.50  -0.63  -0.14   \n",
       "201706  -2.65  -1.20  -1.00  -0.20   2.69  -0.19   9.38   5.49   1.93   4.39   \n",
       "201707   1.52   1.18  -6.06   4.98   2.34   1.79   1.25   0.45   1.03   1.22   \n",
       "201708  -2.77   0.94  -0.96  -1.78  -6.37  -0.04  -5.79   1.69   1.52   2.62   \n",
       "201709   0.43  -3.00  -2.13   3.66   3.54  -0.21   1.01   1.40   6.58   0.45   \n",
       "201710   0.71   1.24  -2.90   2.02  -1.90  -3.09   3.47  -2.35   5.52   1.23   \n",
       "201711   4.15   4.33   1.34   3.30  10.00   4.55   7.94   2.28   2.17   3.80   \n",
       "201712  -0.10   4.31   4.87   0.80   1.06   2.31   4.65  -0.32   0.49  -1.77   \n",
       "\n",
       "           ...      Telcm.lead  Servs.lead  BusEq.lead  Paper.lead  \\\n",
       "yyyymm     ...                                                       \n",
       "192708     ...            6.32        1.94        3.96        3.16   \n",
       "192709     ...           -2.34        4.72       -4.91       -0.11   \n",
       "192710     ...            2.62        2.09        9.17       16.66   \n",
       "192711     ...            1.11       -8.05        1.08        0.82   \n",
       "192712     ...            0.05        0.31        0.93        1.26   \n",
       "192801     ...           -0.63       -0.85        1.69        0.53   \n",
       "192802     ...            1.67       -2.73        2.94       10.79   \n",
       "192803     ...            3.00        2.20        1.38       -0.47   \n",
       "192804     ...            6.29        0.46        3.56        5.81   \n",
       "192805     ...           -5.53       -5.56       -3.37       -6.05   \n",
       "192806     ...           -1.60       -5.26        5.02        4.02   \n",
       "192807     ...            4.23       14.84        2.69       12.37   \n",
       "192808     ...           -0.12       -0.44        1.54       -1.89   \n",
       "192809     ...            2.56        4.81        0.72       -5.88   \n",
       "192810     ...            6.30       17.39        7.84        4.72   \n",
       "192811     ...           -0.44       -7.69        7.43        1.54   \n",
       "192812     ...           13.04       -0.98        2.50        5.60   \n",
       "192901     ...           -1.51       10.66        1.08        5.43   \n",
       "192902     ...            3.95       -1.76        1.58        1.18   \n",
       "192903     ...            3.03        3.58        3.92        7.77   \n",
       "192904     ...           -9.21       -5.36       -1.79       -8.70   \n",
       "192905     ...           13.18       18.49        9.47       12.29   \n",
       "192906     ...           13.35       -1.06        5.39        6.48   \n",
       "192907     ...           10.58       -4.11        8.58        9.05   \n",
       "192908     ...           -1.72       38.35        9.45       -4.94   \n",
       "192909     ...          -15.85      -14.05      -19.39      -15.30   \n",
       "192910     ...           -9.84      -10.35      -22.33      -14.58   \n",
       "192911     ...            0.64       -2.20        3.83       -0.67   \n",
       "192912     ...            1.06      -48.99        9.29        7.46   \n",
       "193001     ...            6.76       58.60        7.15        8.02   \n",
       "...        ...             ...         ...         ...         ...   \n",
       "201507     ...           -8.42       -5.29       -6.50       -5.69   \n",
       "201508     ...           -2.63       -1.47       -1.72       -2.66   \n",
       "201509     ...            8.84       11.26        8.16       10.19   \n",
       "201510     ...           -1.92        1.99        0.12       -0.02   \n",
       "201511     ...           -3.03       -1.19       -4.64       -3.75   \n",
       "201512     ...           -0.36       -5.09       -7.95       -5.27   \n",
       "201601     ...            1.15       -2.45        1.45        2.99   \n",
       "201602     ...            6.00        7.76        8.86        8.18   \n",
       "201603     ...            0.59       -2.55       -5.46        0.80   \n",
       "201604     ...            0.30        4.67        5.64        1.79   \n",
       "201605     ...            3.10       -2.12       -1.63        2.06   \n",
       "201606     ...            2.27        7.33        8.20        2.52   \n",
       "201607     ...           -3.56        1.19        2.38        2.46   \n",
       "201608     ...            0.52        0.82        4.33       -0.64   \n",
       "201609     ...           -2.85       -0.55       -2.24       -5.49   \n",
       "201610     ...            6.25       -0.01        2.39        4.21   \n",
       "201611     ...            4.65       -0.19        2.07        1.86   \n",
       "201612     ...            3.36        5.45        3.20        2.28   \n",
       "201701     ...           -0.11        3.23        6.99        3.21   \n",
       "201702     ...            0.81        1.81        2.45        0.26   \n",
       "201703     ...           -0.16        3.83        0.99        2.06   \n",
       "201704     ...           -2.00        3.60        4.57        2.60   \n",
       "201705     ...           -2.33       -0.82       -3.44        1.87   \n",
       "201706     ...            5.25        3.98        3.05       -2.42   \n",
       "201707     ...           -2.58        1.36        4.98        0.72   \n",
       "201708     ...           -1.68        0.60        0.80        2.44   \n",
       "201709     ...           -5.75        5.93        7.12        4.28   \n",
       "201710     ...            3.91        0.05        2.41        4.21   \n",
       "201711     ...            4.41        0.39       -0.89       -0.95   \n",
       "201712     ...            3.08        9.25        5.02        4.28   \n",
       "\n",
       "        Trans.lead  Whlsl.lead  Rtail.lead  Meals.lead  Fin.lead  Other.lead  \n",
       "yyyymm                                                                        \n",
       "192708        4.10        5.39        7.40        5.73      5.96        0.22  \n",
       "192709       -4.84      -22.03       -5.28       -2.00      3.85       -3.87  \n",
       "192710        3.70       -1.51       11.90        2.80      7.79       10.98  \n",
       "192711       -0.12       11.23       -0.88       -1.78     10.86        0.85  \n",
       "192712       -1.48       -1.20       -1.10       -1.83      1.20       -3.63  \n",
       "192801       -1.68       -8.62       -1.37       -2.92     -3.12       -3.01  \n",
       "192802        5.49        7.83        8.40        3.18      9.28        8.56  \n",
       "192803        4.15       -6.07       -0.25        0.25      8.65       10.73  \n",
       "192804       -0.78        7.63        3.12       13.80      1.96       -1.12  \n",
       "192805       -4.15       -7.72       -3.71       -3.12    -10.22      -12.26  \n",
       "192806       -0.67        0.03        5.40       -0.92     -0.03       -1.12  \n",
       "192807        3.70        3.74       13.37       12.05      4.91       12.46  \n",
       "192808        0.01        0.78       -0.11       -0.29     11.87       -4.33  \n",
       "192809       -1.71       17.84        5.69       -2.60      2.19       -5.62  \n",
       "192810        8.97       11.57       15.14        9.13      9.62        3.39  \n",
       "192811        0.19       -3.91       -1.30       -3.16      1.11      -12.65  \n",
       "192812        4.41       -5.29       -4.31       -0.46      7.92        0.87  \n",
       "192901       -1.82       -3.55       -2.85       -0.20      0.47       -6.54  \n",
       "192902       -3.17       -9.91       -5.47       -3.87     -1.56       -7.75  \n",
       "192903        0.94        3.22        3.20       10.01      0.10      -11.09  \n",
       "192904        2.08       -6.98       -9.29       -3.34     -3.64      -13.65  \n",
       "192905        5.45       -3.49        8.69       18.59      5.82        4.56  \n",
       "192906        7.99       -3.34        0.64        1.50      8.10        4.16  \n",
       "192907        7.97       -6.19        7.76        4.31      5.73       -3.39  \n",
       "192908       -8.10       -1.01       -5.88       -3.56     -6.28       -0.53  \n",
       "192909       -8.45      -23.66      -24.61      -20.05    -29.86      -33.09  \n",
       "192910       -8.22       -7.04      -13.11      -10.65    -14.39      -15.67  \n",
       "192911       -0.44       -1.18       -6.80        3.30     -0.21       -9.03  \n",
       "192912        3.74        2.97        4.32       11.59      9.54       31.64  \n",
       "193001        1.83       -4.92       -5.65       -0.15      5.83       -2.27  \n",
       "...            ...         ...         ...         ...       ...         ...  \n",
       "201507       -6.37       -4.13       -5.44       -6.48     -6.54       -5.20  \n",
       "201508       -0.71       -6.04       -1.75        0.44     -3.14       -1.87  \n",
       "201509        6.48        5.07        4.56        5.05      5.90        6.98  \n",
       "201510       -1.10        2.67        0.61       -1.01      2.16        0.05  \n",
       "201511       -5.02       -1.88        0.82       -0.95     -2.92        0.25  \n",
       "201512       -8.53       -8.68       -4.45       -0.94     -9.63       -3.20  \n",
       "201601        6.89        3.85       -0.36        1.03     -2.85        2.71  \n",
       "201602        6.86        6.18        5.99        5.36      6.65        6.68  \n",
       "201603       -1.08        0.49       -0.38       -2.38      3.96        0.67  \n",
       "201604       -2.18        1.78        1.19       -1.48      2.15       -2.02  \n",
       "201605       -2.53        1.81        0.71        1.16     -5.30        3.61  \n",
       "201606        5.39        3.65        3.78        2.19      4.04       -0.21  \n",
       "201607        1.09       -1.03       -1.69       -0.24      4.88        2.24  \n",
       "201608        2.86       -2.56       -0.18       -2.25     -1.45       -3.48  \n",
       "201609       -0.64       -8.18       -3.59       -1.96      1.40       -0.53  \n",
       "201610       12.75        9.29        2.99        8.47     12.84        8.29  \n",
       "201611        0.84        2.34       -0.98        0.58      3.80        2.57  \n",
       "201612        1.70        1.69        0.93        0.71      0.56       -0.87  \n",
       "201701        2.56        2.73        2.79        2.35      4.58        3.71  \n",
       "201702       -2.80       -1.29        0.80        2.73     -2.26       -1.83  \n",
       "201703        2.14       -2.96        3.21        4.30      0.18       -1.06  \n",
       "201704        2.68        2.56        0.45        6.93     -1.03       -0.74  \n",
       "201705        3.38        0.15       -2.45       -2.54      5.70        1.31  \n",
       "201706       -4.49       -0.99        0.93       -2.63      1.86        1.44  \n",
       "201707        0.60       -4.55       -1.81        1.26     -1.31        1.53  \n",
       "201708        6.20        4.46        2.71        0.79      5.07        0.99  \n",
       "201709       -1.99       -1.18        3.22        3.64      3.22       -1.20  \n",
       "201710        6.66        3.37        9.38        5.45      3.76        1.60  \n",
       "201711        2.73        4.21        2.45        1.18      0.88        1.14  \n",
       "201712        2.56        4.84       11.37        3.12      6.00        5.41  \n",
       "\n",
       "[1085 rows x 150 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "data = pd.read_csv(\"30_Industry_Portfolios.csv\")\n",
    "data = data.set_index('yyyymm')\n",
    "industries = list(data.columns)\n",
    "# map industry names to col nums\n",
    "ind_reverse_dict = dict([(industries[i], i) for i in range(len(industries))])\n",
    "\n",
    "rfdata = pd.read_csv(\"F-F_Research_Data_Factors.csv\")\n",
    "rfdata = rfdata.set_index('yyyymm')\n",
    "data['rf'] = rfdata['RF']\n",
    "\n",
    "# subtract risk-free rate\n",
    "# create a response variable led by 1 period to predict\n",
    "for ind in industries:\n",
    "    data[ind] = data[ind] - data['rf']\n",
    "\n",
    "for ind in industries:\n",
    "    data[ind+\".3m\"] = pd.rolling_mean(data[ind],3)\n",
    "\n",
    "for ind in industries:\n",
    "    data[ind+\".6m\"] = pd.rolling_mean(data[ind],6)\n",
    "\n",
    "for ind in industries:\n",
    "    data[ind+\".12m\"] = pd.rolling_mean(data[ind],12)\n",
    "    \n",
    "for ind in industries:\n",
    "    data[ind+\".lead\"] = data[ind].shift(-1)\n",
    "\n",
    "allcols = list(data.columns[:120])\n",
    "all_reverse_dict = dict([(allcols[i], i) for i in range(len(allcols))])\n",
    "\n",
    "data = data.drop(columns=['rf'])    \n",
    "data = data.dropna(axis=0, how='any')\n",
    "    \n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Games</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>Chems</th>\n",
       "      <th>Txtls</th>\n",
       "      <th>...</th>\n",
       "      <th>Telcm.lead</th>\n",
       "      <th>Servs.lead</th>\n",
       "      <th>BusEq.lead</th>\n",
       "      <th>Paper.lead</th>\n",
       "      <th>Trans.lead</th>\n",
       "      <th>Whlsl.lead</th>\n",
       "      <th>Rtail.lead</th>\n",
       "      <th>Meals.lead</th>\n",
       "      <th>Fin.lead</th>\n",
       "      <th>Other.lead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yyyymm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195912</th>\n",
       "      <td>2.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-3.02</td>\n",
       "      <td>1.64</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.87</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-7.93</td>\n",
       "      <td>-9.41</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>-6.09</td>\n",
       "      <td>-10.08</td>\n",
       "      <td>-4.68</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196001</th>\n",
       "      <td>-4.49</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>-7.84</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-6.68</td>\n",
       "      <td>-10.03</td>\n",
       "      <td>-4.77</td>\n",
       "      <td>...</td>\n",
       "      <td>8.07</td>\n",
       "      <td>9.13</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196002</th>\n",
       "      <td>3.35</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.39</td>\n",
       "      <td>9.31</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>3.34</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-3.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196003</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>2.18</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>7.14</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>8.86</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196004</th>\n",
       "      <td>1.17</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>1.35</td>\n",
       "      <td>6.46</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.49</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>11.90</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196005</th>\n",
       "      <td>8.20</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>2.44</td>\n",
       "      <td>7.28</td>\n",
       "      <td>11.67</td>\n",
       "      <td>7.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-8.07</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.17</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.72</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196006</th>\n",
       "      <td>5.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.38</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196007</th>\n",
       "      <td>-2.11</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>4.60</td>\n",
       "      <td>-4.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.94</td>\n",
       "      <td>5.69</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196008</th>\n",
       "      <td>4.57</td>\n",
       "      <td>3.24</td>\n",
       "      <td>5.20</td>\n",
       "      <td>7.16</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>-7.61</td>\n",
       "      <td>-7.37</td>\n",
       "      <td>-7.07</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>-8.57</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>-4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196009</th>\n",
       "      <td>-3.88</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>-9.18</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.54</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196010</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.38</td>\n",
       "      <td>6.48</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.06</td>\n",
       "      <td>9.49</td>\n",
       "      <td>8.19</td>\n",
       "      <td>5.31</td>\n",
       "      <td>5.35</td>\n",
       "      <td>9.72</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.40</td>\n",
       "      <td>7.71</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196011</th>\n",
       "      <td>9.46</td>\n",
       "      <td>6.57</td>\n",
       "      <td>5.44</td>\n",
       "      <td>13.91</td>\n",
       "      <td>10.11</td>\n",
       "      <td>9.13</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.04</td>\n",
       "      <td>...</td>\n",
       "      <td>12.29</td>\n",
       "      <td>8.18</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.57</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.56</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196012</th>\n",
       "      <td>4.51</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>3.54</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.28</td>\n",
       "      <td>6.06</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>...</td>\n",
       "      <td>7.70</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.56</td>\n",
       "      <td>8.35</td>\n",
       "      <td>7.93</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.08</td>\n",
       "      <td>7.12</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196101</th>\n",
       "      <td>4.70</td>\n",
       "      <td>5.23</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.47</td>\n",
       "      <td>4.36</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.46</td>\n",
       "      <td>11.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.54</td>\n",
       "      <td>6.83</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.82</td>\n",
       "      <td>8.23</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196102</th>\n",
       "      <td>4.21</td>\n",
       "      <td>8.16</td>\n",
       "      <td>5.41</td>\n",
       "      <td>22.33</td>\n",
       "      <td>2.15</td>\n",
       "      <td>5.90</td>\n",
       "      <td>7.84</td>\n",
       "      <td>5.05</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.81</td>\n",
       "      <td>...</td>\n",
       "      <td>7.23</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>2.31</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.76</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196103</th>\n",
       "      <td>4.64</td>\n",
       "      <td>2.55</td>\n",
       "      <td>5.60</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.77</td>\n",
       "      <td>6.34</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196104</th>\n",
       "      <td>-1.39</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-5.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.39</td>\n",
       "      <td>4.74</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>4.31</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196105</th>\n",
       "      <td>4.20</td>\n",
       "      <td>5.38</td>\n",
       "      <td>3.39</td>\n",
       "      <td>-3.91</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.47</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-3.31</td>\n",
       "      <td>-4.46</td>\n",
       "      <td>-4.57</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196106</th>\n",
       "      <td>-2.17</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>3.97</td>\n",
       "      <td>-5.87</td>\n",
       "      <td>-3.85</td>\n",
       "      <td>3.43</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.35</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196107</th>\n",
       "      <td>2.72</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.95</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8.99</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.37</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.65</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196108</th>\n",
       "      <td>4.92</td>\n",
       "      <td>3.20</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10.45</td>\n",
       "      <td>5.21</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-6.04</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-6.21</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196109</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>6.53</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.16</td>\n",
       "      <td>4.30</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196110</th>\n",
       "      <td>3.73</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>7.05</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>8.28</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.34</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>5.65</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196111</th>\n",
       "      <td>5.28</td>\n",
       "      <td>4.47</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.51</td>\n",
       "      <td>5.30</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.49</td>\n",
       "      <td>7.37</td>\n",
       "      <td>...</td>\n",
       "      <td>3.14</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196112</th>\n",
       "      <td>-3.69</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-6.12</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-3.66</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.32</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>-6.91</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-9.56</td>\n",
       "      <td>-3.90</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196201</th>\n",
       "      <td>-6.67</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>-13.23</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-7.37</td>\n",
       "      <td>-5.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>-4.76</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>3.89</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>3.59</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196202</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>-1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196203</th>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-6.67</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.31</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-12.01</td>\n",
       "      <td>-7.93</td>\n",
       "      <td>-6.27</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>-2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196204</th>\n",
       "      <td>-4.59</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-12.99</td>\n",
       "      <td>-11.04</td>\n",
       "      <td>-8.74</td>\n",
       "      <td>-7.03</td>\n",
       "      <td>-8.01</td>\n",
       "      <td>-11.23</td>\n",
       "      <td>-6.23</td>\n",
       "      <td>-7.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-10.97</td>\n",
       "      <td>-13.19</td>\n",
       "      <td>-11.03</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>-11.34</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>-7.46</td>\n",
       "      <td>-10.02</td>\n",
       "      <td>-11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196205</th>\n",
       "      <td>-11.25</td>\n",
       "      <td>-9.05</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>-11.39</td>\n",
       "      <td>-14.87</td>\n",
       "      <td>-10.19</td>\n",
       "      <td>-10.01</td>\n",
       "      <td>-11.14</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>-7.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.72</td>\n",
       "      <td>-13.11</td>\n",
       "      <td>-12.59</td>\n",
       "      <td>-9.62</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-10.43</td>\n",
       "      <td>-12.90</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-14.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201507</th>\n",
       "      <td>4.03</td>\n",
       "      <td>3.51</td>\n",
       "      <td>9.59</td>\n",
       "      <td>6.09</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.66</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.42</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>-5.69</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-4.13</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-6.54</td>\n",
       "      <td>-5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201508</th>\n",
       "      <td>-4.37</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-8.61</td>\n",
       "      <td>-6.94</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>-8.37</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-6.04</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201509</th>\n",
       "      <td>-1.19</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.37</td>\n",
       "      <td>-9.94</td>\n",
       "      <td>-5.32</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-7.28</td>\n",
       "      <td>-8.38</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>8.84</td>\n",
       "      <td>11.26</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10.19</td>\n",
       "      <td>6.48</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201510</th>\n",
       "      <td>5.81</td>\n",
       "      <td>8.06</td>\n",
       "      <td>10.90</td>\n",
       "      <td>14.61</td>\n",
       "      <td>12.21</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7.74</td>\n",
       "      <td>16.62</td>\n",
       "      <td>7.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201511</th>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-5.02</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201512</th>\n",
       "      <td>1.96</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>1.86</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-5.09</td>\n",
       "      <td>-7.95</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-8.68</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-9.63</td>\n",
       "      <td>-3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>4.28</td>\n",
       "      <td>-8.15</td>\n",
       "      <td>-5.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-9.43</td>\n",
       "      <td>-11.10</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.99</td>\n",
       "      <td>6.89</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0.95</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.18</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.36</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>4.69</td>\n",
       "      <td>5.61</td>\n",
       "      <td>5.04</td>\n",
       "      <td>8.61</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>8.33</td>\n",
       "      <td>3.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>-5.46</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-6.30</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>2.06</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-4.96</td>\n",
       "      <td>2.46</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>2.06</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>4.75</td>\n",
       "      <td>5.31</td>\n",
       "      <td>6.87</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.52</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>4.04</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201607</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.15</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.29</td>\n",
       "      <td>8.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201608</th>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4.33</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>2.86</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-3.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.92</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201610</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>4.59</td>\n",
       "      <td>5.59</td>\n",
       "      <td>-10.28</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.21</td>\n",
       "      <td>12.75</td>\n",
       "      <td>9.29</td>\n",
       "      <td>2.99</td>\n",
       "      <td>8.47</td>\n",
       "      <td>12.84</td>\n",
       "      <td>8.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>-4.41</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>3.87</td>\n",
       "      <td>8.15</td>\n",
       "      <td>-4.18</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>4.65</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.34</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>4.43</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.39</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.45</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701</th>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>5.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.79</td>\n",
       "      <td>6.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>3.23</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.35</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201702</th>\n",
       "      <td>1.71</td>\n",
       "      <td>6.13</td>\n",
       "      <td>7.93</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3.81</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201703</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.79</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.94</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201704</th>\n",
       "      <td>0.76</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.24</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.57</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.93</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201705</th>\n",
       "      <td>1.63</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201706</th>\n",
       "      <td>-2.65</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.49</td>\n",
       "      <td>1.93</td>\n",
       "      <td>4.39</td>\n",
       "      <td>...</td>\n",
       "      <td>5.25</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201707</th>\n",
       "      <td>1.52</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201708</th>\n",
       "      <td>-2.77</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-5.79</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.62</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.44</td>\n",
       "      <td>6.20</td>\n",
       "      <td>4.46</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201709</th>\n",
       "      <td>0.43</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.54</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>5.93</td>\n",
       "      <td>7.12</td>\n",
       "      <td>4.28</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.22</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201710</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>2.02</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>3.47</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.41</td>\n",
       "      <td>4.21</td>\n",
       "      <td>6.66</td>\n",
       "      <td>3.37</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.45</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201711</th>\n",
       "      <td>4.15</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>7.94</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>2.73</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4.65</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>...</td>\n",
       "      <td>3.08</td>\n",
       "      <td>9.25</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.56</td>\n",
       "      <td>4.84</td>\n",
       "      <td>11.37</td>\n",
       "      <td>3.12</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows  150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food  Beer  Smoke  Games  Books  Hshld  Clths   Hlth  Chems  Txtls  \\\n",
       "yyyymm                                                                        \n",
       "195912   2.01  0.35  -3.02   1.64   7.29   0.67   1.87  -1.97   3.08   0.74   \n",
       "196001  -4.49 -5.71  -2.05   1.21  -5.47  -7.84  -8.53  -6.68 -10.03  -4.77   \n",
       "196002   3.35 -2.14   2.27   4.23   2.39   9.31   1.44  -0.02  -0.74   0.32   \n",
       "196003  -1.67 -2.94  -0.18  -0.65   2.18  -0.56  -2.59   1.26  -2.75  -6.79   \n",
       "196004   1.17 -2.16   1.35   6.46  -1.17  -1.27   0.21   1.49  -5.53  -1.10   \n",
       "196005   8.20 -0.52   2.44   7.28  11.67   7.74   1.74  13.50   3.40   2.10   \n",
       "196006   5.39  0.47   4.73   2.24   0.02   6.38  -1.59  -0.40   0.45   4.04   \n",
       "196007  -2.11 -0.79   4.60  -4.72   0.23  -0.60  -1.10  -3.99  -6.80  -3.14   \n",
       "196008   4.57  3.24   5.20   7.16   3.63   5.09   3.34   2.29   1.17  -0.84   \n",
       "196009  -3.88 -5.00  -2.09  -2.33  -6.20  -9.18  -4.23  -8.87  -6.70  -5.25   \n",
       "196010   1.02  0.54   3.87   0.11   2.38   6.48  -3.50  -3.71  -1.59  -3.06   \n",
       "196011   9.46  6.57   5.44  13.91  10.11   9.13   3.15   3.91   4.25   2.04   \n",
       "196012   4.51 -0.31   3.54   7.77   7.41   1.76   3.28   6.06   2.85   0.52   \n",
       "196101   4.70  5.23   8.77   0.56   9.47   4.36   5.94   5.86   6.46  11.21   \n",
       "196102   4.21  8.16   5.41  22.33   2.15   5.90   7.84   5.05   2.13   6.81   \n",
       "196103   4.64  2.55   5.60   7.18   4.77   6.34   3.08   3.60   0.92   5.92   \n",
       "196104  -1.39  1.40  -0.23  -2.21  -6.37   2.66   2.60  -0.47  -1.47  -5.31   \n",
       "196105   4.20  5.38   3.39  -3.91   2.71  -0.02   6.80   2.10   5.50   5.47   \n",
       "196106  -2.17 -3.12   3.97  -5.87  -3.85   3.43  -5.50  -3.58  -1.32  -3.36   \n",
       "196107   2.72  0.88   5.95  -1.21  -2.55   1.97   2.03   3.27   2.95   1.53   \n",
       "196108   4.92  3.20   7.74   0.89   0.89  10.45   5.21   3.70   2.35   5.77   \n",
       "196109  -0.62 -1.48  -0.07   1.24   0.75  -3.05  -1.14  -1.48  -4.45  -4.25   \n",
       "196110   3.73 -0.84   7.05  -5.26   0.99  -0.67   8.28   3.33   0.05   3.11   \n",
       "196111   5.28  4.47   8.03   0.25   3.75   4.51   5.30   3.12   2.49   7.37   \n",
       "196112  -3.69  1.41  -6.12   1.97  -3.66  -3.78   0.32  -2.21  -0.16  -1.17   \n",
       "196201  -6.67 -3.45  -4.28 -13.23  -3.44  -7.37  -5.89  -4.86  -4.76   0.57   \n",
       "196202  -0.25  0.28   0.68  -2.02  -0.52  -0.90   2.01   3.56   3.30   1.93   \n",
       "196203   0.98 -0.34  -6.67  -5.34   0.41   4.31  -1.18   0.34  -2.72  -0.74   \n",
       "196204  -4.59 -3.59 -12.99 -11.04  -8.74  -7.03  -8.01 -11.23  -6.23  -7.53   \n",
       "196205 -11.25 -9.05 -14.14 -11.39 -14.87 -10.19 -10.01 -11.14  -8.25  -7.50   \n",
       "...       ...   ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "201507   4.03  3.51   9.59   6.09  -2.90   0.71   5.96   3.66  -4.90  -0.72   \n",
       "201508  -4.37 -3.12  -4.06  -7.35  -8.61  -6.94  -3.86  -8.37  -7.15  -3.11   \n",
       "201509  -1.19  2.58   2.37  -9.94  -5.32  -0.53   1.18  -7.28  -8.38  -5.92   \n",
       "201510   5.81  8.06  10.90  14.61  12.21   5.81   0.98   7.74  16.62   7.96   \n",
       "201511   0.11 -0.71  -3.00  -0.41  -1.17  -1.10  -1.08   0.71   1.68  -2.59   \n",
       "201512   1.96  0.30   1.59  -1.70  -6.18   1.86  -4.38   0.39  -4.82  -2.65   \n",
       "201601  -1.67 -0.23   4.28  -8.15  -5.28   0.16   1.52  -9.43 -11.10  -5.33   \n",
       "201602   0.95 -2.34   0.93   4.25  -0.96   0.34   0.81  -1.09   6.79   0.63   \n",
       "201603   4.69  5.61   5.04   8.61   6.88   4.65   2.30   2.90   8.33   3.58   \n",
       "201604   0.63  0.31  -0.25  -6.30   1.82  -0.42  -2.27   3.55   3.77   1.55   \n",
       "201605   2.06 -0.91   0.83   5.42  -0.53  -0.09  -4.96   2.46  -1.42  -1.70   \n",
       "201606   4.75  5.31   6.87  -4.43  -0.34   3.16   1.63   0.11  -1.14  -4.67   \n",
       "201607  -0.51  1.82  -2.79   6.15   7.38   2.58   1.62   6.00   4.29   8.39   \n",
       "201608  -0.52 -0.90  -1.22   0.94   0.29   1.24   1.37  -3.24   2.48   1.03   \n",
       "201609  -2.92  1.63  -2.78   4.62  -3.95   0.00  -6.92   0.35  -1.76  -4.87   \n",
       "201610  -0.33 -1.65   4.59   5.59 -10.28  -2.96  -5.76  -7.45  -1.95  -4.17   \n",
       "201611  -4.41 -5.76  -5.12   3.87   8.15  -4.18   1.80   1.37   7.55   1.58   \n",
       "201612   4.43  3.00   5.39  -3.36   1.98   1.43  -0.44   0.82   0.32  -1.27   \n",
       "201701   0.95 -1.02   5.61   4.84   1.60   2.72  -0.01   2.17   3.79   6.90   \n",
       "201702   1.71  6.13   7.93   0.65  -0.39   4.83   3.81   7.03   3.10  -2.12   \n",
       "201703   0.52  0.89   1.03   5.79  -0.92  -0.36   0.32  -0.19   2.17   1.94   \n",
       "201704   0.76  1.89  -0.14   2.74  -0.83  -0.36  -1.24   1.06   1.28   3.24   \n",
       "201705   1.63  4.28   6.12   2.80  -1.71   1.77  -2.17  -0.50  -0.63  -0.14   \n",
       "201706  -2.65 -1.20  -1.00  -0.20   2.69  -0.19   9.38   5.49   1.93   4.39   \n",
       "201707   1.52  1.18  -6.06   4.98   2.34   1.79   1.25   0.45   1.03   1.22   \n",
       "201708  -2.77  0.94  -0.96  -1.78  -6.37  -0.04  -5.79   1.69   1.52   2.62   \n",
       "201709   0.43 -3.00  -2.13   3.66   3.54  -0.21   1.01   1.40   6.58   0.45   \n",
       "201710   0.71  1.24  -2.90   2.02  -1.90  -3.09   3.47  -2.35   5.52   1.23   \n",
       "201711   4.15  4.33   1.34   3.30  10.00   4.55   7.94   2.28   2.17   3.80   \n",
       "201712  -0.10  4.31   4.87   0.80   1.06   2.31   4.65  -0.32   0.49  -1.77   \n",
       "\n",
       "           ...      Telcm.lead  Servs.lead  BusEq.lead  Paper.lead  \\\n",
       "yyyymm     ...                                                       \n",
       "195912     ...            0.62       -6.18       -7.93       -9.41   \n",
       "196001     ...            8.07        9.13        5.09        3.00   \n",
       "196002     ...           -0.21       -0.31        3.34       -2.43   \n",
       "196003     ...           -1.24        7.14        1.77        0.41   \n",
       "196004     ...            3.05       -1.75       11.90        2.85   \n",
       "196005     ...           -0.58       -8.07        2.39        3.50   \n",
       "196006     ...           -0.03        2.84       -2.02       -4.10   \n",
       "196007     ...            6.94        5.69        2.71        1.18   \n",
       "196008     ...           -6.07       -3.53       -7.61       -7.37   \n",
       "196009     ...           -0.08        4.62       -3.40       -1.85   \n",
       "196010     ...            4.06        9.49        8.19        5.31   \n",
       "196011     ...           12.29        8.18        4.29        5.57   \n",
       "196012     ...            7.70        4.29        5.08        4.56   \n",
       "196101     ...            0.61        0.20        4.54        6.83   \n",
       "196102     ...            7.23       -0.20        2.31       -0.69   \n",
       "196103     ...            0.63       -0.12        2.19       -0.37   \n",
       "196104     ...           -1.22       -0.70        1.57        1.39   \n",
       "196105     ...           -4.19        0.13       -3.31       -4.46   \n",
       "196106     ...            6.25       -8.25        0.56       -0.50   \n",
       "196107     ...            0.12        8.99        5.11        5.37   \n",
       "196108     ...           -2.94       -6.04        1.01       -2.74   \n",
       "196109     ...            0.00        2.24        6.53        1.74   \n",
       "196110     ...            8.34        8.27        0.99        2.05   \n",
       "196111     ...            3.14       -0.68       -0.55       -2.65   \n",
       "196112     ...           -6.32       -4.88       -6.91       -5.22   \n",
       "196201     ...            3.89       -1.94       -0.07        3.87   \n",
       "196202     ...           -3.14       -1.41       -0.76        1.13   \n",
       "196203     ...           -4.93       -3.11      -12.01       -7.93   \n",
       "196204     ...           -7.35      -10.97      -13.19      -11.03   \n",
       "196205     ...           -8.72      -13.11      -12.59       -9.62   \n",
       "...        ...             ...         ...         ...         ...   \n",
       "201507     ...           -8.42       -5.29       -6.50       -5.69   \n",
       "201508     ...           -2.63       -1.47       -1.72       -2.66   \n",
       "201509     ...            8.84       11.26        8.16       10.19   \n",
       "201510     ...           -1.92        1.99        0.12       -0.02   \n",
       "201511     ...           -3.03       -1.19       -4.64       -3.75   \n",
       "201512     ...           -0.36       -5.09       -7.95       -5.27   \n",
       "201601     ...            1.15       -2.45        1.45        2.99   \n",
       "201602     ...            6.00        7.76        8.86        8.18   \n",
       "201603     ...            0.59       -2.55       -5.46        0.80   \n",
       "201604     ...            0.30        4.67        5.64        1.79   \n",
       "201605     ...            3.10       -2.12       -1.63        2.06   \n",
       "201606     ...            2.27        7.33        8.20        2.52   \n",
       "201607     ...           -3.56        1.19        2.38        2.46   \n",
       "201608     ...            0.52        0.82        4.33       -0.64   \n",
       "201609     ...           -2.85       -0.55       -2.24       -5.49   \n",
       "201610     ...            6.25       -0.01        2.39        4.21   \n",
       "201611     ...            4.65       -0.19        2.07        1.86   \n",
       "201612     ...            3.36        5.45        3.20        2.28   \n",
       "201701     ...           -0.11        3.23        6.99        3.21   \n",
       "201702     ...            0.81        1.81        2.45        0.26   \n",
       "201703     ...           -0.16        3.83        0.99        2.06   \n",
       "201704     ...           -2.00        3.60        4.57        2.60   \n",
       "201705     ...           -2.33       -0.82       -3.44        1.87   \n",
       "201706     ...            5.25        3.98        3.05       -2.42   \n",
       "201707     ...           -2.58        1.36        4.98        0.72   \n",
       "201708     ...           -1.68        0.60        0.80        2.44   \n",
       "201709     ...           -5.75        5.93        7.12        4.28   \n",
       "201710     ...            3.91        0.05        2.41        4.21   \n",
       "201711     ...            4.41        0.39       -0.89       -0.95   \n",
       "201712     ...            3.08        9.25        5.02        4.28   \n",
       "\n",
       "        Trans.lead  Whlsl.lead  Rtail.lead  Meals.lead  Fin.lead  Other.lead  \n",
       "yyyymm                                                                        \n",
       "195912       -4.31       -5.33       -6.09      -10.08     -4.68       -3.98  \n",
       "196001       -0.94        1.42        4.00        1.81     -0.98        6.32  \n",
       "196002       -4.99       -1.37       -0.13       -3.88      0.05       -2.43  \n",
       "196003       -2.13        0.45       -0.53        8.86     -0.64        0.55  \n",
       "196004        0.90        1.65        3.11        0.80     -0.45        1.02  \n",
       "196005        2.17        5.96        3.41        1.03      3.72        6.41  \n",
       "196006       -3.11       -6.16       -2.99       -1.25      0.09       -5.95  \n",
       "196007        1.98        4.51        2.85        2.05      3.47        3.48  \n",
       "196008       -7.07       -8.44       -8.57       -1.90     -5.78       -4.21  \n",
       "196009       -1.02       -4.22        0.31       -4.54     -0.40        0.38  \n",
       "196010        5.35        9.72        6.50        4.40      7.71        4.01  \n",
       "196011        2.27        2.06        2.05        2.08      5.56        3.80  \n",
       "196012        8.35        7.93        2.28        4.08      7.12        8.23  \n",
       "196101        4.22        3.31        4.82        8.23      7.00        6.00  \n",
       "196102        0.86        4.45        5.76        4.06      4.34        7.08  \n",
       "196103       -1.62        3.08        0.22        4.23      1.38       -3.67  \n",
       "196104        4.74       -0.04        4.31       -1.90      4.00        3.32  \n",
       "196105       -4.57       -4.90        0.80       -5.63     -2.88        0.37  \n",
       "196106       -0.32       -0.01        2.45        2.69      3.35        5.37  \n",
       "196107        3.52        3.09        3.03        0.46      8.65        1.64  \n",
       "196108       -1.16       -4.22        0.66       -6.21     -0.40        3.14  \n",
       "196109        2.16        4.30        9.35        0.71      2.02        0.39  \n",
       "196110        0.47        5.65        4.90        1.08      7.22        1.69  \n",
       "196111       -0.24        0.46       -0.63       -2.21     -4.44       -0.77  \n",
       "196112        2.52       -0.79       -9.56       -3.90     -4.99       -3.62  \n",
       "196201        0.32       -0.09        1.58       -0.59      3.59        4.20  \n",
       "196202       -1.68       -2.30        0.90       -4.07     -2.13       -1.83  \n",
       "196203       -6.27       -5.78       -4.61       -9.09     -7.69       -2.12  \n",
       "196204       -5.17      -11.34       -9.09       -7.46    -10.02      -11.83  \n",
       "196205       -7.81      -11.11      -10.43      -12.90    -11.01      -14.25  \n",
       "...            ...         ...         ...         ...       ...         ...  \n",
       "201507       -6.37       -4.13       -5.44       -6.48     -6.54       -5.20  \n",
       "201508       -0.71       -6.04       -1.75        0.44     -3.14       -1.87  \n",
       "201509        6.48        5.07        4.56        5.05      5.90        6.98  \n",
       "201510       -1.10        2.67        0.61       -1.01      2.16        0.05  \n",
       "201511       -5.02       -1.88        0.82       -0.95     -2.92        0.25  \n",
       "201512       -8.53       -8.68       -4.45       -0.94     -9.63       -3.20  \n",
       "201601        6.89        3.85       -0.36        1.03     -2.85        2.71  \n",
       "201602        6.86        6.18        5.99        5.36      6.65        6.68  \n",
       "201603       -1.08        0.49       -0.38       -2.38      3.96        0.67  \n",
       "201604       -2.18        1.78        1.19       -1.48      2.15       -2.02  \n",
       "201605       -2.53        1.81        0.71        1.16     -5.30        3.61  \n",
       "201606        5.39        3.65        3.78        2.19      4.04       -0.21  \n",
       "201607        1.09       -1.03       -1.69       -0.24      4.88        2.24  \n",
       "201608        2.86       -2.56       -0.18       -2.25     -1.45       -3.48  \n",
       "201609       -0.64       -8.18       -3.59       -1.96      1.40       -0.53  \n",
       "201610       12.75        9.29        2.99        8.47     12.84        8.29  \n",
       "201611        0.84        2.34       -0.98        0.58      3.80        2.57  \n",
       "201612        1.70        1.69        0.93        0.71      0.56       -0.87  \n",
       "201701        2.56        2.73        2.79        2.35      4.58        3.71  \n",
       "201702       -2.80       -1.29        0.80        2.73     -2.26       -1.83  \n",
       "201703        2.14       -2.96        3.21        4.30      0.18       -1.06  \n",
       "201704        2.68        2.56        0.45        6.93     -1.03       -0.74  \n",
       "201705        3.38        0.15       -2.45       -2.54      5.70        1.31  \n",
       "201706       -4.49       -0.99        0.93       -2.63      1.86        1.44  \n",
       "201707        0.60       -4.55       -1.81        1.26     -1.31        1.53  \n",
       "201708        6.20        4.46        2.71        0.79      5.07        0.99  \n",
       "201709       -1.99       -1.18        3.22        3.64      3.22       -1.20  \n",
       "201710        6.66        3.37        9.38        5.45      3.76        1.60  \n",
       "201711        2.73        4.21        2.45        1.18      0.88        1.14  \n",
       "201712        2.56        4.84       11.37        3.12      6.00        5.41  \n",
       "\n",
       "[697 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use data >= 195912 for consistency with paper\n",
    "# but keep data > 2016 to be as current and have as much data as possible\n",
    "data = data.loc[data.index[data.index > 195911]]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 12, 120)\n",
      "(685, 30)\n"
     ]
    }
   ],
   "source": [
    "# roll up X so each row contains 12 previous months * 120 cols\n",
    "# create training, CV, test sets\n",
    "# multi-output: simultaneously train all estimators, forcing 1st layer look for common patterns and inputs\n",
    "# add regularization\n",
    "# add dropout\n",
    "\n",
    "npredictors=120\n",
    "nresponses = 30\n",
    "lookback = 12\n",
    "\n",
    "X_raw = data.values[:,:npredictors]\n",
    "Y = data.values[12:, -nresponses:]\n",
    "numrows = Y.shape[0]\n",
    "\n",
    "# each input will have shape 12 * npredictors\n",
    "X = np.zeros([numrows, lookback, npredictors])\n",
    "for row in range(numrows):\n",
    "    prev12 = []\n",
    "    for i in range(lookback):\n",
    "        prev12.append(X_raw[row + i])\n",
    "    X[row] = np.vstack(prev12)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LSTM model\n",
    "# input (360)\n",
    "# -> LSTM\n",
    "# -> Dropout\n",
    "# -> LSTM\n",
    "# -> Dropout\n",
    "# -> 30 Dense linear outputs (1 per industry)\n",
    "\n",
    "INPUT_DIM = npredictors\n",
    "OUTPUT_DIM = nresponses\n",
    "\n",
    "def build_model(hidden_layers = [[16, 0.0001, 0.2], \n",
    "                                 [16, 0.0001, 0.2], \n",
    "                                 [1, 0.0, 0.0]],\n",
    "                verbose=True):\n",
    "    \"\"\"Take list of [layer_size, reg_penalty, dropout], last layer is linear, rest LSTM\"\"\"\n",
    "\n",
    "    main_input = Input(shape=(None, \n",
    "                              INPUT_DIM), \n",
    "                       dtype='float32', \n",
    "                       name='main_input')\n",
    "    lastlayer=main_input\n",
    "\n",
    "    n_lstms = len(hidden_layers)-1\n",
    "    for i in range(n_lstms):\n",
    "        layer_size, reg_penalty, dropout = hidden_layers[i]\n",
    "        if verbose:\n",
    "            print(\"layer %d size %d, reg_penalty %.8f, dropout %.3f\" % (i, layer_size, reg_penalty, dropout))\n",
    "\n",
    "        # first n-1 layers are GRU, return_sequences=True\n",
    "        # nth layer is GRU, return_sequences=False\n",
    "        return_sequences = True\n",
    "        if i == n_lstms-1:\n",
    "            return_sequences= False\n",
    "        lastlayer = GRU(layer_size, \n",
    "                        return_sequences=return_sequences,\n",
    "                        kernel_regularizer=keras.regularizers.l1(reg_penalty),\n",
    "                        dropout=dropout, \n",
    "                        recurrent_dropout=dropout,\n",
    "                        name = \"GRU%02d\" % i\n",
    "                       )(lastlayer)\n",
    "        \n",
    "    layer_size, reg_penalty, dropout = hidden_layers[-1]\n",
    "    if dropout:\n",
    "        lastlayer = Dropout(dropout, name=\"Dropout%02d\" % (i+1))(lastlayer)\n",
    "\n",
    "    # OUTPUT_DIM outputs\n",
    "    outputs = []\n",
    "    for i in range(OUTPUT_DIM):\n",
    "        outputs.append(Dense(1, \n",
    "                             activation='linear', \n",
    "                             kernel_regularizer=keras.regularizers.l1(reg_penalty),\n",
    "                             name='output%02d' % i)(lastlayer)\n",
    "                      )\n",
    "    \n",
    "    model = Model(inputs=[main_input], outputs=outputs)\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    model.compile(loss=\"mae\", metrics=['mae'], optimizer=\"rmsprop\", loss_weights=[1.]*OUTPUT_DIM)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODELPREFIX = \"GRU\"\n",
    "EPOCHS = 160\n",
    "#VAL_SPLIT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "LOOKBACK = 128\n",
    "BATCH_SIZE = 64\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def run_experiment (layer1_size = 16, \n",
    "                    layer2_size = 16, \n",
    "                    layer1_reg_penalty=0.0,\n",
    "                    layer2_reg_penalty=0.0,\n",
    "                    layer1_dropout=0.25,\n",
    "                    layer2_dropout=0.25,\n",
    "                    layer3_reg_penalty=0.001,\n",
    "                    layer3_dropout=0.25\n",
    "                   ):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # generate k-folds\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    kf.get_n_splits(X)\n",
    "    last_indexes = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # use test_index as last index to train\n",
    "        last_index = test_index[-1] + 1\n",
    "        last_indexes.append(last_index)\n",
    "\n",
    "    print(\"%s Generate splits %s\" % (time.strftime(\"%H:%M:%S\"), str([i for i in last_indexes])))\n",
    "    \n",
    "    avg_bests = []\n",
    "    \n",
    "    print(\"%s Build model\" % (time.strftime(\"%H:%M:%S\")))\n",
    "    \n",
    "    model = build_model([[layer1_size, layer1_reg_penalty, layer1_dropout],\n",
    "                         [layer2_size, layer2_reg_penalty, layer2_dropout],\n",
    "                         [1, layer3_reg_penalty, layer3_dropout],\n",
    "                        ])\n",
    "    print(\"Compile time : %s\" % str(time.time() - start))\n",
    "    print(\"Starting to train : %s\" % (time.strftime(\"%H:%M:%S\")))\n",
    "\n",
    "    for i in range(1, n_splits-1):\n",
    "        \n",
    "        models = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        count = 0        \n",
    "        # skip kfold 0 so you start with train 2x size of eval set\n",
    "        last_train_index = last_indexes[i]\n",
    "        last_xval_index = last_indexes[i+1]\n",
    "\n",
    "        # set up train, xval\n",
    "        # train from beginning to last_train_index\n",
    "        print(\"Training indexes 0 to %d\" % (last_train_index-1))\n",
    "        X_fit = X[:last_train_index]\n",
    "        Y_fit = Y[:last_train_index]\n",
    "        # xval from last_train_index to last_xval_index\n",
    "        print(\"Cross-validating indexes %d to %d\" % (last_train_index, last_xval_index -1 ))\n",
    "        X_xval = X[last_train_index:last_xval_index]\n",
    "        Y_xval = Y[last_train_index:last_xval_index]\n",
    "\n",
    "        responses = []\n",
    "        for i in range(nresponses):\n",
    "            responses.append(Y_fit[:,i])\n",
    "        # train for EPOCHS\n",
    "        for epoch in range(EPOCHS):\n",
    "            fit = model.fit(\n",
    "                X_fit,\n",
    "                responses,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                #validation_split=VAL_SPLIT,\n",
    "                epochs=1,\n",
    "                verbose=0)\n",
    "            \n",
    "            train_loss = fit.history['loss'][-1]\n",
    "            # evaluate ... run prediction, calc MSE by industry, and average\n",
    "            y_xval_pred = np.array(model.predict(X_xval))\n",
    "            y_xval_pred = y_xval_pred.reshape(Y_xval.T.shape)\n",
    "            y_xval_pred = y_xval_pred.T\n",
    "            mse_list = []\n",
    "            for i in range(len(industries)):\n",
    "                mse_list.append(mean_squared_error(Y_xval[:,i], y_xval_pred[:,i]))\n",
    "            xval_score = np.mean(np.array(mse_list))            \n",
    "            \n",
    "            losses.append(train_loss)\n",
    "            scores.append(xval_score)\n",
    "            models.append(copy.copy(model))\n",
    "\n",
    "            bestloss_index = np.argmin(scores)\n",
    "            bestloss_value = scores[bestloss_index]\n",
    "\n",
    "            sys.stdout.write('.')\n",
    "            count += 1\n",
    "            if count % 80 == 0:\n",
    "                print(\"\")\n",
    "                print(\"%s Still training\" % (time.strftime(\"%H:%M:%S\")))\n",
    "            sys.stdout.flush()            \n",
    "            \n",
    "            # stop if loss rises by 20% from best\n",
    "            if xval_score / bestloss_value > 1.2:\n",
    "                print(\"Stopping early...\" )\n",
    "                break\n",
    "\n",
    "        # choose model with lowest xval loss\n",
    "        print(\"\")\n",
    "        print (\"%s Best Xval loss epoch %d, value %f\" % (time.strftime(\"%H:%M:%S\"), bestloss_index, bestloss_value))\n",
    "        avg_bests.append(bestloss_value)\n",
    "        model = models[bestloss_index]\n",
    "    \n",
    "    print (\"Last Xval loss %f\" % (bestloss_value))\n",
    "    avg_loss = np.mean(np.array(avg_bests))\n",
    "    print (\"Avg Xval loss %f\" % avg_loss)\n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "    return (avg_loss, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:23:17 Generate splits [137, 274, 411, 548, 685]\n",
      "22:23:17 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           1584        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,670\n",
      "Trainable params: 8,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.0510661602020264\n",
      "Starting to train : 22:23:18\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "................................................................................\n",
      "22:24:23 Still training\n",
      "................................................................................\n",
      "22:24:59 Still training\n",
      "\n",
      "22:24:59 Best Xval loss epoch 133, value 32.148647\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "................................................................................\n",
      "22:25:48 Still training\n",
      "................................................................................\n",
      "22:26:36 Still training\n",
      "\n",
      "22:26:36 Best Xval loss epoch 16, value 43.096946\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................\n",
      "22:27:35 Still training\n",
      "................................................................................\n",
      "22:28:34 Still training\n",
      "\n",
      "22:28:34 Best Xval loss epoch 145, value 41.869454\n",
      "Last Xval loss 41.869454\n",
      "Avg Xval loss 39.038349\n",
      "--------------------------------------------------------------------------------\n",
      "39.038349197569545\n"
     ]
    }
   ],
   "source": [
    "score, model = run_experiment()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:22:11 Running 18 experiments\n",
      "21:22:11 Running experiment 1 of 18\n",
      "21:22:11 Generate splits [137, 274, 411, 548, 685]\n",
      "21:22:11 Build model\n",
      "layer 0 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 4, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 8)      3096        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 4)            156         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 4)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,402\n",
      "Trainable params: 3,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.056610107421875\n",
      "Starting to train : 21:22:12\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:22:45 Best Xval loss epoch 49, value 33.004507\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:23:12 Best Xval loss epoch 27, value 41.096664\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:23:45 Best Xval loss epoch 5, value 42.075607\n",
      "Last Xval loss 42.075607\n",
      "Avg Xval loss 38.725593\n",
      "--------------------------------------------------------------------------------\n",
      "21:23:45 Running experiment 2 of 18\n",
      "21:23:45 Generate splits [137, 274, 411, 548, 685]\n",
      "21:23:45 Build model\n",
      "layer 0 size 8, reg_penalty 0.00000000, dropout 0.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 size 4, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 8)      3096        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 4)            156         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 4)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,402\n",
      "Trainable params: 3,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.617844581604004\n",
      "Starting to train : 21:23:47\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:24:20 Best Xval loss epoch 41, value 32.874162\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:24:47 Best Xval loss epoch 34, value 41.012004\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:25:21 Best Xval loss epoch 29, value 41.323048\n",
      "Last Xval loss 41.323048\n",
      "Avg Xval loss 38.403071\n",
      "--------------------------------------------------------------------------------\n",
      "21:25:21 Running experiment 3 of 18\n",
      "21:25:21 Generate splits [137, 274, 411, 548, 685]\n",
      "21:25:21 Build model\n",
      "layer 0 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 8)      3096        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 8)            408         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 8)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,774\n",
      "Trainable params: 3,774\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile time : 1.1610066890716553\n",
      "Starting to train : 21:25:23\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:25:57 Best Xval loss epoch 48, value 32.831582\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:26:25 Best Xval loss epoch 45, value 41.049425\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:27:00 Best Xval loss epoch 14, value 41.957562\n",
      "Last Xval loss 41.957562\n",
      "Avg Xval loss 38.612856\n",
      "--------------------------------------------------------------------------------\n",
      "21:27:00 Running experiment 4 of 18\n",
      "21:27:00 Generate splits [137, 274, 411, 548, 685]\n",
      "21:27:00 Build model\n",
      "layer 0 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 8)      3096        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 8)            408         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 8)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,774\n",
      "Trainable params: 3,774\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1664743423461914\n",
      "Starting to train : 21:27:01\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:27:36 Best Xval loss epoch 48, value 32.784666\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:28:04 Best Xval loss epoch 38, value 41.024682\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:28:39 Best Xval loss epoch 5, value 41.664234\n",
      "Last Xval loss 41.664234\n",
      "Avg Xval loss 38.491194\n",
      "--------------------------------------------------------------------------------\n",
      "21:28:39 Running experiment 5 of 18\n",
      "21:28:39 Generate splits [137, 274, 411, 548, 685]\n",
      "21:28:39 Build model\n",
      "layer 0 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 8)      3096        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           1200        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,806\n",
      "Trainable params: 4,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.827152967453003\n",
      "Starting to train : 21:28:41\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:29:17 Best Xval loss epoch 48, value 32.491571\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:29:45 Best Xval loss epoch 2, value 40.985676\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:30:21 Best Xval loss epoch 3, value 41.952545\n",
      "Last Xval loss 41.952545\n",
      "Avg Xval loss 38.476597\n",
      "--------------------------------------------------------------------------------\n",
      "21:30:21 Running experiment 6 of 18\n",
      "21:30:21 Generate splits [137, 274, 411, 548, 685]\n",
      "21:30:21 Build model\n",
      "layer 0 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 8)      3096        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           1200        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,806\n",
      "Trainable params: 4,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1664068698883057\n",
      "Starting to train : 21:30:22\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:30:59 Best Xval loss epoch 29, value 33.191752\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:31:28 Best Xval loss epoch 11, value 41.125649\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:32:04 Best Xval loss epoch 15, value 43.123092\n",
      "Last Xval loss 43.123092\n",
      "Avg Xval loss 39.146831\n",
      "--------------------------------------------------------------------------------\n",
      "21:32:04 Running experiment 7 of 18\n",
      "21:32:04 Generate splits [137, 274, 411, 548, 685]\n",
      "21:32:04 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 4, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 4)            252         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 4)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,978\n",
      "Trainable params: 6,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.995530605316162\n",
      "Starting to train : 21:32:06\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:32:44 Best Xval loss epoch 48, value 32.875602\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:33:12 Best Xval loss epoch 28, value 41.083122\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:33:48 Best Xval loss epoch 23, value 41.610948\n",
      "Last Xval loss 41.610948\n",
      "Avg Xval loss 38.523224\n",
      "--------------------------------------------------------------------------------\n",
      "21:33:48 Running experiment 8 of 18\n",
      "21:33:48 Generate splits [137, 274, 411, 548, 685]\n",
      "21:33:48 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 size 4, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 4)            252         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 4)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,978\n",
      "Trainable params: 6,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.177804708480835\n",
      "Starting to train : 21:33:49\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:34:28 Best Xval loss epoch 48, value 33.078823\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:34:56 Best Xval loss epoch 32, value 41.083178\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:35:31 Best Xval loss epoch 20, value 42.373249\n",
      "Last Xval loss 42.373249\n",
      "Avg Xval loss 38.845083\n",
      "--------------------------------------------------------------------------------\n",
      "21:35:31 Running experiment 9 of 18\n",
      "21:35:31 Generate splits [137, 274, 411, 548, 685]\n",
      "21:35:31 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 8)            600         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 8)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,446\n",
      "Trainable params: 7,446\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile time : 1.1762802600860596\n",
      "Starting to train : 21:35:32\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:36:13 Best Xval loss epoch 45, value 32.841647\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:36:42 Best Xval loss epoch 8, value 41.033472\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:37:19 Best Xval loss epoch 3, value 42.366848\n",
      "Last Xval loss 42.366848\n",
      "Avg Xval loss 38.747322\n",
      "--------------------------------------------------------------------------------\n",
      "21:37:19 Running experiment 10 of 18\n",
      "21:37:19 Generate splits [137, 274, 411, 548, 685]\n",
      "21:37:19 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 8)            600         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 8)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,446\n",
      "Trainable params: 7,446\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1516478061676025\n",
      "Starting to train : 21:37:20\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:38:01 Best Xval loss epoch 49, value 33.063317\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:38:30 Best Xval loss epoch 32, value 40.853438\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:39:05 Best Xval loss epoch 0, value 42.338338\n",
      "Last Xval loss 42.338338\n",
      "Avg Xval loss 38.751698\n",
      "--------------------------------------------------------------------------------\n",
      "21:39:05 Running experiment 11 of 18\n",
      "21:39:05 Generate splits [137, 274, 411, 548, 685]\n",
      "21:39:05 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           1584        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,670\n",
      "Trainable params: 8,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1134464740753174\n",
      "Starting to train : 21:39:06\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:39:47 Best Xval loss epoch 29, value 32.920843\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:40:15 Best Xval loss epoch 4, value 41.062251\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:40:50 Best Xval loss epoch 9, value 41.762761\n",
      "Last Xval loss 41.762761\n",
      "Avg Xval loss 38.581952\n",
      "--------------------------------------------------------------------------------\n",
      "21:40:50 Running experiment 12 of 18\n",
      "21:40:50 Generate splits [137, 274, 411, 548, 685]\n",
      "21:40:50 Build model\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           1584        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,670\n",
      "Trainable params: 8,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1227784156799316\n",
      "Starting to train : 21:40:51\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:41:33 Best Xval loss epoch 49, value 32.773073\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:42:02 Best Xval loss epoch 1, value 41.522610\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:42:38 Best Xval loss epoch 15, value 41.111046\n",
      "Last Xval loss 41.111046\n",
      "Avg Xval loss 38.468910\n",
      "--------------------------------------------------------------------------------\n",
      "21:42:38 Running experiment 13 of 18\n",
      "21:42:38 Generate splits [137, 274, 411, 548, 685]\n",
      "21:42:38 Build model\n",
      "layer 0 size 32, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 4, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 32)     14688       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 4)            444         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 4)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,282\n",
      "Trainable params: 15,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.192701816558838\n",
      "Starting to train : 21:42:39\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:43:22 Best Xval loss epoch 40, value 32.905410\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:43:50 Best Xval loss epoch 20, value 40.854727\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:44:27 Best Xval loss epoch 1, value 42.771757\n",
      "Last Xval loss 42.771757\n",
      "Avg Xval loss 38.843965\n",
      "--------------------------------------------------------------------------------\n",
      "21:44:27 Running experiment 14 of 18\n",
      "21:44:27 Generate splits [137, 274, 411, 548, 685]\n",
      "21:44:27 Build model\n",
      "layer 0 size 32, reg_penalty 0.00000000, dropout 0.250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 size 4, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 32)     14688       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 4)            444         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 4)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            5           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,282\n",
      "Trainable params: 15,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.193312168121338\n",
      "Starting to train : 21:44:28\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:45:11 Best Xval loss epoch 47, value 33.102722\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:45:41 Best Xval loss epoch 39, value 41.076290\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:46:19 Best Xval loss epoch 5, value 42.360449\n",
      "Last Xval loss 42.360449\n",
      "Avg Xval loss 38.846487\n",
      "--------------------------------------------------------------------------------\n",
      "21:46:19 Running experiment 15 of 18\n",
      "21:46:19 Generate splits [137, 274, 411, 548, 685]\n",
      "21:46:19 Build model\n",
      "layer 0 size 32, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 32)     14688       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 8)            984         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 8)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,942\n",
      "Trainable params: 15,942\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile time : 1.2021899223327637\n",
      "Starting to train : 21:46:20\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:47:04 Best Xval loss epoch 49, value 32.724735\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:47:35 Best Xval loss epoch 0, value 41.932191\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:48:13 Best Xval loss epoch 10, value 42.865423\n",
      "Last Xval loss 42.865423\n",
      "Avg Xval loss 39.174116\n",
      "--------------------------------------------------------------------------------\n",
      "21:48:13 Running experiment 16 of 18\n",
      "21:48:13 Generate splits [137, 274, 411, 548, 685]\n",
      "21:48:13 Build model\n",
      "layer 0 size 32, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 8, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 32)     14688       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 8)            984         GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 8)            0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            9           Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,942\n",
      "Trainable params: 15,942\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1757333278656006\n",
      "Starting to train : 21:48:14\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:49:00 Best Xval loss epoch 42, value 32.512065\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:49:30 Best Xval loss epoch 5, value 41.242924\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:50:09 Best Xval loss epoch 13, value 41.946548\n",
      "Last Xval loss 41.946548\n",
      "Avg Xval loss 38.567179\n",
      "--------------------------------------------------------------------------------\n",
      "21:50:09 Running experiment 17 of 18\n",
      "21:50:09 Generate splits [137, 274, 411, 548, 685]\n",
      "21:50:09 Build model\n",
      "layer 0 size 32, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 32)     14688       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           2352        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,550\n",
      "Trainable params: 17,550\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.184041976928711\n",
      "Starting to train : 21:50:10\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:50:56 Best Xval loss epoch 48, value 32.256803\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:51:26 Best Xval loss epoch 0, value 41.807466\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n",
      "..................................................\n",
      "21:52:03 Best Xval loss epoch 1, value 41.326265\n",
      "Last Xval loss 41.326265\n",
      "Avg Xval loss 38.463512\n",
      "--------------------------------------------------------------------------------\n",
      "21:52:03 Running experiment 18 of 18\n",
      "21:52:03 Generate splits [137, 274, 411, 548, 685]\n",
      "21:52:03 Build model\n",
      "layer 0 size 32, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 32)     14688       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           2352        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,550\n",
      "Trainable params: 17,550\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Compile time : 1.1691641807556152\n",
      "Starting to train : 21:52:04\n",
      "Training indexes 0 to 273\n",
      "Cross-validating indexes 274 to 410\n",
      "..................................................\n",
      "21:52:51 Best Xval loss epoch 49, value 32.761535\n",
      "Training indexes 0 to 410\n",
      "Cross-validating indexes 411 to 547\n",
      "..................................................\n",
      "21:53:21 Best Xval loss epoch 11, value 41.519896\n",
      "Training indexes 0 to 547\n",
      "Cross-validating indexes 548 to 684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "21:53:59 Best Xval loss epoch 3, value 44.187688\n",
      "Last Xval loss 44.187688\n",
      "Avg Xval loss 39.489706\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# run in big xval loop\n",
    "# do predictions\n",
    "# compute mse\n",
    "# save data to pick best hyperparameters\n",
    "\n",
    "layer1_sizes = [8, 16, 32]\n",
    "layer2_sizes = [4, 8, 16]\n",
    "layer1_reg_penalties = [0.0]\n",
    "layer2_reg_penalties = [0.0]\n",
    "layer3_reg_penalties = [0.001, 0.0001]\n",
    "layer1_dropouts = [0.25]\n",
    "layer2_dropouts = [0.25]\n",
    "layer3_dropouts = [0.25]\n",
    "\n",
    "hyperparameter_combos = list(product(layer1_sizes,\n",
    "                                     layer2_sizes,\n",
    "                                     layer1_reg_penalties,\n",
    "                                     layer2_reg_penalties,\n",
    "                                     layer3_reg_penalties,\n",
    "                                     layer1_dropouts,\n",
    "                                     layer2_dropouts,\n",
    "                                     layer3_dropouts,\n",
    "                                    ))\n",
    "\n",
    "print(\"%s Running %d experiments\" % (time.strftime(\"%H:%M:%S\"), len(hyperparameter_combos)))\n",
    "\n",
    "experiments = {}\n",
    "\n",
    "for counter, param_list in enumerate(hyperparameter_combos):\n",
    "    layer1_size, layer2_size, layer1_reg_penalty, layer2_reg_penalty, layer3_reg_penalty, layer1_dropout, layer2_dropout, layer3_dropout = param_list\n",
    "    print(\"%s Running experiment %d of %d\" % (time.strftime(\"%H:%M:%S\"), counter+1, len(hyperparameter_combos)))\n",
    "    key = (layer1_size, layer1_reg_penalty, layer1_dropout, layer2_size, layer2_reg_penalty, layer2_dropout, layer3_reg_penalty, layer3_dropout)\n",
    "    experiments[key], model = run_experiment(layer1_size=layer1_size,\n",
    "                                             layer1_reg_penalty=layer1_reg_penalty,\n",
    "                                             layer1_dropout=layer1_dropout,\n",
    "                                             layer2_size=layer2_size,\n",
    "                                             layer2_reg_penalty=layer2_reg_penalty,\n",
    "                                             layer2_dropout=layer2_dropout,\n",
    "                                             layer3_reg_penalty=layer3_reg_penalty,\n",
    "                                             layer3_dropout=layer3_dropout\n",
    "                                            )\n",
    "    modelname = \"%s_%d_%.6f\" % (MODELPREFIX, counter, experiments[key])\n",
    "    print(\"%s Saving %s.h5\" % (time.strftime(\"%H:%M:%S\"), modelname))\n",
    "    model.save(\"%s.h5\" % modelname)\n",
    "    model.save_weights(\"%s_weights.h5\" % modelname)    \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 0.0, 0.25, 4, 0.0, 0.25, 0.0001, 0.25): 38.40307148621994,\n",
       " (8, 0.0, 0.25, 4, 0.0, 0.25, 0.001, 0.25): 38.72559272263172,\n",
       " (8, 0.0, 0.25, 8, 0.0, 0.25, 0.0001, 0.25): 38.49119367961723,\n",
       " (8, 0.0, 0.25, 8, 0.0, 0.25, 0.001, 0.25): 38.61285636867233,\n",
       " (8, 0.0, 0.25, 16, 0.0, 0.25, 0.0001, 0.25): 39.146831413538415,\n",
       " (8, 0.0, 0.25, 16, 0.0, 0.25, 0.001, 0.25): 38.47659704043105,\n",
       " (16, 0.0, 0.25, 4, 0.0, 0.25, 0.0001, 0.25): 38.84508341226216,\n",
       " (16, 0.0, 0.25, 4, 0.0, 0.25, 0.001, 0.25): 38.52322376703327,\n",
       " (16, 0.0, 0.25, 8, 0.0, 0.25, 0.0001, 0.25): 38.75169783360641,\n",
       " (16, 0.0, 0.25, 8, 0.0, 0.25, 0.001, 0.25): 38.747322424780755,\n",
       " (16, 0.0, 0.25, 16, 0.0, 0.25, 0.0001, 0.25): 38.468909621847,\n",
       " (16, 0.0, 0.25, 16, 0.0, 0.25, 0.001, 0.25): 38.58195176391808,\n",
       " (32, 0.0, 0.25, 4, 0.0, 0.25, 0.0001, 0.25): 38.846487146766954,\n",
       " (32, 0.0, 0.25, 4, 0.0, 0.25, 0.001, 0.25): 38.8439647648184,\n",
       " (32, 0.0, 0.25, 8, 0.0, 0.25, 0.0001, 0.25): 38.56717915891477,\n",
       " (32, 0.0, 0.25, 8, 0.0, 0.25, 0.001, 0.25): 39.174116181715554,\n",
       " (32, 0.0, 0.25, 16, 0.0, 0.25, 0.0001, 0.25): 39.48970598438231,\n",
       " (32, 0.0, 0.25, 16, 0.0, 0.25, 0.001, 0.25): 38.46351155915598}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer1_size</th>\n",
       "      <th>layer1_reg_penalty</th>\n",
       "      <th>layer1_dropout</th>\n",
       "      <th>layer2_size</th>\n",
       "      <th>layer2_reg_penalty</th>\n",
       "      <th>layer2_dropout</th>\n",
       "      <th>layer3_reg_penalty</th>\n",
       "      <th>layer3_dropout</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.403071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.463512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.468910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.476597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.491194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.523224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.567179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.581952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.612856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.725593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.747322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.751698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.843965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.845083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>38.846487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>39.146831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>39.174116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>39.489706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer1_size  layer1_reg_penalty  layer1_dropout  layer2_size  \\\n",
       "1             8                 0.0            0.25            4   \n",
       "16           32                 0.0            0.25           16   \n",
       "11           16                 0.0            0.25           16   \n",
       "4             8                 0.0            0.25           16   \n",
       "3             8                 0.0            0.25            8   \n",
       "6            16                 0.0            0.25            4   \n",
       "15           32                 0.0            0.25            8   \n",
       "10           16                 0.0            0.25           16   \n",
       "2             8                 0.0            0.25            8   \n",
       "0             8                 0.0            0.25            4   \n",
       "8            16                 0.0            0.25            8   \n",
       "9            16                 0.0            0.25            8   \n",
       "12           32                 0.0            0.25            4   \n",
       "7            16                 0.0            0.25            4   \n",
       "13           32                 0.0            0.25            4   \n",
       "5             8                 0.0            0.25           16   \n",
       "14           32                 0.0            0.25            8   \n",
       "17           32                 0.0            0.25           16   \n",
       "\n",
       "    layer2_reg_penalty  layer2_dropout  layer3_reg_penalty  layer3_dropout  \\\n",
       "1                  0.0            0.25              0.0001            0.25   \n",
       "16                 0.0            0.25              0.0010            0.25   \n",
       "11                 0.0            0.25              0.0001            0.25   \n",
       "4                  0.0            0.25              0.0010            0.25   \n",
       "3                  0.0            0.25              0.0001            0.25   \n",
       "6                  0.0            0.25              0.0010            0.25   \n",
       "15                 0.0            0.25              0.0001            0.25   \n",
       "10                 0.0            0.25              0.0010            0.25   \n",
       "2                  0.0            0.25              0.0010            0.25   \n",
       "0                  0.0            0.25              0.0010            0.25   \n",
       "8                  0.0            0.25              0.0010            0.25   \n",
       "9                  0.0            0.25              0.0001            0.25   \n",
       "12                 0.0            0.25              0.0010            0.25   \n",
       "7                  0.0            0.25              0.0001            0.25   \n",
       "13                 0.0            0.25              0.0001            0.25   \n",
       "5                  0.0            0.25              0.0001            0.25   \n",
       "14                 0.0            0.25              0.0010            0.25   \n",
       "17                 0.0            0.25              0.0001            0.25   \n",
       "\n",
       "         loss  \n",
       "1   38.403071  \n",
       "16  38.463512  \n",
       "11  38.468910  \n",
       "4   38.476597  \n",
       "3   38.491194  \n",
       "6   38.523224  \n",
       "15  38.567179  \n",
       "10  38.581952  \n",
       "2   38.612856  \n",
       "0   38.725593  \n",
       "8   38.747322  \n",
       "9   38.751698  \n",
       "12  38.843965  \n",
       "7   38.845083  \n",
       "13  38.846487  \n",
       "5   39.146831  \n",
       "14  39.174116  \n",
       "17  39.489706  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe with columns as loss keys + loss value\n",
    "flatlist = [list(l[0]) + [l[1]] for l in experiments.items()]\n",
    "lossframe = pd.DataFrame(flatlist, columns=[\"layer1_size\",\n",
    "                                            \"layer1_reg_penalty\",\n",
    "                                            \"layer1_dropout\",\n",
    "                                            \"layer2_size\",\n",
    "                                            \"layer2_reg_penalty\",\n",
    "                                            \"layer2_dropout\",\n",
    "                                            \"layer3_reg_penalty\",\n",
    "                                            \"layer3_dropout\",\n",
    "                                            \"loss\"\n",
    "                                           ])\n",
    "lossframe = lossframe.sort_values(['loss'])\n",
    "lossframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.642690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38.653031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>38.897494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  loss\n",
       "layer1_size           \n",
       "8            38.642690\n",
       "16           38.653031\n",
       "32           38.897494"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort each column by mean loss\n",
    "pd.DataFrame(lossframe.groupby(['layer1_size'])['loss'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2_size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.697904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.724061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38.771251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  loss\n",
       "layer2_size           \n",
       "4            38.697904\n",
       "8            38.724061\n",
       "16           38.771251"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lossframe.groupby(['layer2_size'])['loss'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer3_reg_penalty</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>38.778907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>38.683237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         loss\n",
       "layer3_reg_penalty           \n",
       "0.0001              38.778907\n",
       "0.0010              38.683237"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lossframe.groupby(['layer3_reg_penalty'])['loss'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer3_dropout</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>38.731072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     loss\n",
       "layer3_dropout           \n",
       "0.25            38.731072"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lossframe.groupby(['layer3_dropout'])['loss'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer2_size</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer1_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.564332</td>\n",
       "      <td>38.552025</td>\n",
       "      <td>38.811714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38.684154</td>\n",
       "      <td>38.749510</td>\n",
       "      <td>38.525431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>38.845226</td>\n",
       "      <td>38.870648</td>\n",
       "      <td>38.976609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  loss                      \n",
       "layer2_size         4          8          16\n",
       "layer1_size                                 \n",
       "8            38.564332  38.552025  38.811714\n",
       "16           38.684154  38.749510  38.525431\n",
       "32           38.845226  38.870648  38.976609"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossframe.pivot_table(index=['layer1_size'], columns=['layer2_size'], values=['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4  units', '8  units', '16  units'] ['8  units', '16  units', '32  units']\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(0,0,255)",
           [
            1,
            "rgb(255,0,0)"
           ]
          ]
         ],
         "type": "heatmap",
         "x": [
          "4  units",
          "8  units",
          "16  units"
         ],
         "y": [
          "8  units",
          "16  units",
          "32  units"
         ],
         "z": [
          [
           38.56433210442583,
           38.55202502414478,
           38.81171422698473
          ],
          [
           38.68415358964772,
           38.74951012919358,
           38.52543069288254
          ],
          [
           38.84522595579268,
           38.870647670315165,
           38.97660877176915
          ]
         ]
        }
       ],
       "layout": {
        "height": 480,
        "margin": {
         "b": 120,
         "l": 150,
         "r": 30,
         "t": 100
        },
        "title": "layer1_size v. layer2_size",
        "width": 640,
        "xaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "layer2_size"
        },
        "yaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "layer1_size"
        }
       }
      },
      "text/html": [
       "<div id=\"c904511a-de84-43a1-ad59-73b79c1939b1\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c904511a-de84-43a1-ad59-73b79c1939b1\", [{\"type\": \"heatmap\", \"z\": [[38.56433210442583, 38.55202502414478, 38.81171422698473], [38.68415358964772, 38.74951012919358, 38.52543069288254], [38.84522595579268, 38.870647670315165, 38.97660877176915]], \"x\": [\"4  units\", \"8  units\", \"16  units\"], \"y\": [\"8  units\", \"16  units\", \"32  units\"], \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"layer1_size v. layer2_size\", \"height\": 480, \"width\": 640, \"margin\": {\"l\": 150, \"r\": 30, \"b\": 120, \"t\": 100}, \"xaxis\": {\"title\": \"layer2_size\", \"tickfont\": {\"family\": \"Arial, sans-serif\", \"size\": 10, \"color\": \"black\"}}, \"yaxis\": {\"title\": \"layer1_size\", \"tickfont\": {\"family\": \"Arial, sans-serif\", \"size\": 10, \"color\": \"black\"}}}, {\"showLink\": true, \"linkText\": \"\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"c904511a-de84-43a1-ad59-73b79c1939b1\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c904511a-de84-43a1-ad59-73b79c1939b1\", [{\"type\": \"heatmap\", \"z\": [[38.56433210442583, 38.55202502414478, 38.81171422698473], [38.68415358964772, 38.74951012919358, 38.52543069288254], [38.84522595579268, 38.870647670315165, 38.97660877176915]], \"x\": [\"4  units\", \"8  units\", \"16  units\"], \"y\": [\"8  units\", \"16  units\", \"32  units\"], \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"layer1_size v. layer2_size\", \"height\": 480, \"width\": 640, \"margin\": {\"l\": 150, \"r\": 30, \"b\": 120, \"t\": 100}, \"xaxis\": {\"title\": \"layer2_size\", \"tickfont\": {\"family\": \"Arial, sans-serif\", \"size\": 10, \"color\": \"black\"}}, \"yaxis\": {\"title\": \"layer1_size\", \"tickfont\": {\"family\": \"Arial, sans-serif\", \"size\": 10, \"color\": \"black\"}}}, {\"showLink\": true, \"linkText\": \"\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_matrix(lossframe, x_labels, y_labels, x_suffix=\"\", y_suffix=\"\"):\n",
    "\n",
    "    pivot = lossframe.pivot_table(index=[x_labels], columns=[y_labels], values=['loss'])\n",
    "    # specify labels as strings, to force it to use a discrete axis\n",
    "    if lossframe[x_labels].dtype == np.float64 or lossframe[x_labels].dtype == np.float32:\n",
    "        xaxis = [\"%f %s\" % (i, x_suffix) for i in pivot.columns.levels[1].values]\n",
    "    else:\n",
    "        xaxis = [\"%d %s\" % (i, x_suffix) for i in pivot.columns.levels[1].values]\n",
    "    if lossframe[y_labels].dtype == np.float64 or lossframe[y_labels].dtype == np.float32:\n",
    "        yaxis = [\"%f %s\" % (i, y_suffix) for i in pivot.index.values]\n",
    "    else:\n",
    "        yaxis = [\"%d %s\" % (i, y_suffix) for i in pivot.index.values]\n",
    "        \n",
    "    print(xaxis, yaxis)\n",
    "    \"\"\"plot a heat map of a matrix\"\"\"\n",
    "    chart_width=640\n",
    "    chart_height=480\n",
    "    \n",
    "    layout = Layout(\n",
    "        title=\"%s v. %s\" % (x_labels, y_labels),\n",
    "        height=chart_height,\n",
    "        width=chart_width,     \n",
    "        margin=dict(\n",
    "            l=150,\n",
    "            r=30,\n",
    "            b=120,\n",
    "            t=100,\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title=y_labels,\n",
    "            tickfont=dict(\n",
    "                family='Arial, sans-serif',\n",
    "                size=10,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=x_labels,\n",
    "            tickfont=dict(\n",
    "                family='Arial, sans-serif',\n",
    "                size=10,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    data = [Heatmap(z=pivot.values,\n",
    "                    x=xaxis,\n",
    "                    y=yaxis,\n",
    "                    colorscale=[[0, 'rgb(0,0,255)', [1, 'rgb(255,0,0)']]],\n",
    "                   )\n",
    "           ]\n",
    "\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return iplot(fig, link_text=\"\")\n",
    "\n",
    "plot_matrix(lossframe, \"layer1_size\", \"layer2_size\", x_suffix=\" units\", y_suffix=\" units\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.0668411]], dtype=float32), array([[2.1671436]], dtype=float32), array([[2.6684165]], dtype=float32), array([[2.998097]], dtype=float32), array([[2.3361874]], dtype=float32), array([[2.152578]], dtype=float32), array([[2.7692204]], dtype=float32), array([[2.1950886]], dtype=float32), array([[2.6096902]], dtype=float32), array([[2.7966287]], dtype=float32), array([[2.7754967]], dtype=float32), array([[2.6230006]], dtype=float32), array([[3.0043914]], dtype=float32), array([[2.9483125]], dtype=float32), array([[2.6848085]], dtype=float32), array([[3.4327831]], dtype=float32), array([[2.2238753]], dtype=float32), array([[2.5416346]], dtype=float32), array([[2.1236176]], dtype=float32), array([[1.853823]], dtype=float32), array([[1.7496694]], dtype=float32), array([[2.994804]], dtype=float32), array([[2.684042]], dtype=float32), array([[2.1574578]], dtype=float32), array([[2.8792164]], dtype=float32), array([[2.6844234]], dtype=float32), array([[2.5600595]], dtype=float32), array([[3.1260774]], dtype=float32), array([[2.8187757]], dtype=float32), array([[2.4286833]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0668411,\n",
       " 2.1671436,\n",
       " 2.6684165,\n",
       " 2.998097,\n",
       " 2.3361874,\n",
       " 2.152578,\n",
       " 2.7692204,\n",
       " 2.1950886,\n",
       " 2.6096902,\n",
       " 2.7966287,\n",
       " 2.7754967,\n",
       " 2.6230006,\n",
       " 3.0043914,\n",
       " 2.9483125,\n",
       " 2.6848085,\n",
       " 3.4327831,\n",
       " 2.2238753,\n",
       " 2.5416346,\n",
       " 2.1236176,\n",
       " 1.853823,\n",
       " 1.7496694,\n",
       " 2.994804,\n",
       " 2.684042,\n",
       " 2.1574578,\n",
       " 2.8792164,\n",
       " 2.6844234,\n",
       " 2.5600595,\n",
       " 3.1260774,\n",
       " 2.8187757,\n",
       " 2.4286833]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS=160\n",
    "\n",
    "def fit_predict(X, Y, model):\n",
    "    \"\"\"for backtest, train model using Ys v. X using n-1 rows\n",
    "    predict Ys on X using nth row\n",
    "    return a prediction for month n+1 using X for final month\"\"\"\n",
    "    \n",
    "    # keep last row to predict against\n",
    "    X_predict = X[-1]\n",
    "    X_predict = X_predict.reshape(1,X.shape[1],X.shape[2])\n",
    "    \n",
    "    # fit on remaining rows\n",
    "    X_fit = X[:-1]\n",
    "    Y_fit = Y[:-1]\n",
    "    \n",
    "    Ys = []\n",
    "    for i in range(OUTPUT_DIM):\n",
    "        Ys.append(Y_fit[:,i])\n",
    "        \n",
    "    fit = model.fit(\n",
    "        X_fit,\n",
    "        Ys,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=0)\n",
    "    \n",
    "    return [z[0][0] for z in model.predict(X_predict)]    \n",
    "\n",
    "predictions = fit_predict(X, Y, model)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit and predict all months starting STARTMONTH using data up to that month\n",
    "# compute predictions matrix P\n",
    "# compute returns matrix R using mean(top 6, (-bot 6))\n",
    "\n",
    "def run_backtest(X, Y, arg_dict, startmonth=0):\n",
    "    global P\n",
    "    global R \n",
    "    \n",
    "    print(\"%s Starting backtest\" % (time.strftime(\"%H:%M:%S\")))\n",
    "    print(arg_dict)\n",
    "    P = np.zeros((X.shape[0],OUTPUT_DIM))\n",
    "    count = 0\n",
    "    for month_index in range(startmonth, X.shape[0]+1):\n",
    "        model = build_model([[arg_dict[\"layer1_size\"], arg_dict[\"layer1_reg_penalty\"], arg_dict[\"layer1_dropout\"]],\n",
    "                             [arg_dict[\"layer2_size\"], arg_dict[\"layer2_reg_penalty\"], arg_dict[\"layer2_dropout\"]],\n",
    "                             [1, arg_dict[\"layer3_reg_penalty\"], arg_dict[\"layer3_dropout\"]],\n",
    "                            ])\n",
    "        predictions = fit_predict(X[:month_index, :], \n",
    "                                  Y[:month_index], \n",
    "                                  model)\n",
    "        try:\n",
    "            P[month_index]= predictions\n",
    "            sys.stdout.write('.')\n",
    "            count += 1\n",
    "            if count % 80 == 0:\n",
    "                print(\"\")\n",
    "                print(\"%s Still training\" % (time.strftime(\"%H:%M:%S\")))\n",
    "            sys.stdout.flush()\n",
    "        except IndexError:\n",
    "            # I want to run the fit and see the R-squared on full dataset\n",
    "            # but we are storing the predictions in row of the month predicted\n",
    "            # so we have no row to store the last prediction (2017-01)\n",
    "            print(\"\\nlast prediction not stored\")\n",
    "                \n",
    "    R = np.zeros(P.shape[0])\n",
    "    numstocks = 6 # top quintile (and bottom)\n",
    "\n",
    "    for month_index in range(startmonth, X.shape[0]):\n",
    "        # get indexes of sorted smallest to largest\n",
    "        select_array = np.argsort(P[month_index])\n",
    "        # leftmost 6\n",
    "        short_indexes = select_array[:numstocks]\n",
    "        # rightmost 6\n",
    "        long_indexes = select_array[-numstocks:]\n",
    "        # compute equal weighted long/short return\n",
    "        R[month_index] = np.mean(X[month_index, long_indexes])/2 - np.mean(X[month_index, short_indexes])/2\n",
    "\n",
    "    results = R[startmonth:]\n",
    "\n",
    "    index = pd.date_range('01/01/1970',periods=results.shape[0], freq='M')\n",
    "    perfdata = pd.DataFrame(results,index=index,columns=['Returns'])\n",
    "    perfdata['Equity'] = 100 * np.cumprod(1 + results / 100)\n",
    "\n",
    "    stats = perfdata['Equity'].calc_stats()\n",
    "\n",
    "    retframe = pd.DataFrame([stats.stats.loc['start'],\n",
    "                             stats.stats.loc['end'],\n",
    "                             stats.stats.loc['cagr'],\n",
    "                             stats.stats.loc['yearly_vol'],\n",
    "                             stats.stats.loc['yearly_sharpe'],\n",
    "                             stats.stats.loc['max_drawdown'],\n",
    "                             ffn.core.calc_sortino_ratio(perfdata.Returns, rf=0, nperiods=564, annualize=False),\n",
    "                            ],\n",
    "                            index = ['start',\n",
    "                                     'end',\n",
    "                                     'cagr',\n",
    "                                     'yearly_vol',\n",
    "                                     'yearly_sharpe',\n",
    "                                     'max_drawdown',\n",
    "                                     'sortino',\n",
    "                                    ],\n",
    "                            columns=['Value'])   \n",
    "    return retframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:38:38 Starting backtest\n",
      "{'layer1_size': 16, 'layer1_reg_penalty': 0.0, 'layer1_dropout': 0.25, 'layer2_size': 16, 'layer2_reg_penalty': 0.0, 'layer2_dropout': 0.25, 'layer3_reg_penalty': 0.0, 'layer3_dropout': 0.001, 'verbose': False}\n",
      "layer 0 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "layer 1 size 16, reg_penalty 0.00000000, dropout 0.250\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, None, 120)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "GRU00 (GRU)                     (None, None, 16)     6576        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GRU01 (GRU)                     (None, 16)           1584        GRU00[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout02 (Dropout)             (None, 16)           0           GRU01[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output00 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output01 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output02 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output03 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output04 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output05 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output06 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output07 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output08 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output09 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output10 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output11 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output12 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output13 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output14 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output15 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output16 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output17 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output18 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output19 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output20 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output21 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output22 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output23 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output24 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output25 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output26 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output27 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output28 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output29 (Dense)                (None, 1)            17          Dropout02[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,670\n",
      "Trainable params: 8,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "STARTMONTH=121\n",
    "arg_dict = {\"layer1_size\" : 16,\n",
    "            \"layer1_reg_penalty\" : 0.0,\n",
    "            \"layer1_dropout\": 0.25,\n",
    "            \"layer2_size\": 16,\n",
    "            \"layer2_reg_penalty\" : 0.0,\n",
    "            \"layer2_dropout\" : 0.25,\n",
    "            \"layer3_reg_penalty\" : 0.0,\n",
    "            \"layer3_dropout\" : 0.001,\n",
    "            'verbose' : False\n",
    "           }\n",
    "     \n",
    "#model = build_model(**arg_dict)\n",
    "run_backtest(X, Y, arg_dict, startmonth=STARTMONTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model for EPOCHS on X[:-1]\n",
    "# predict Y[-1] using X[-1], return prediction\n",
    "\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=15\n",
    "OUTPUT_DIM=30\n",
    "\n",
    "def fit_predict(model, X, Y, epochs=EPOCHS):\n",
    "    \"\"\"fit Ys v. X using n-1 rows\n",
    "    predict Ys on X using nth row\n",
    "    return predictions for last month\"\"\"\n",
    "    \n",
    "    # keep last row to predict against\n",
    "    X_predict = X[-1]\n",
    "    X_predict = X_predict.reshape(1,X.shape[1],X.shape[2])\n",
    "    # fit on remaining rows\n",
    "    X_fit = X[:-1]\n",
    "    Y_fit = Y[:-1]\n",
    "\n",
    "    model.compile(loss=\"mae\", metrics=['mae'], optimizer=\"rmsprop\", loss_weights=[1.]*OUTPUT_DIM)\n",
    "    #model.compile(loss=\"mse\", metrics=['mse'], optimizer=\"rmsprop\")\n",
    "\n",
    "    Ys = []\n",
    "    for i in range(OUTPUT_DIM):\n",
    "        Ys.append(Y_fit[:,i])\n",
    "        \n",
    "    fit = model.fit(\n",
    "        X_fit,\n",
    "        Ys,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=epochs,\n",
    "        verbose=0)\n",
    "    \n",
    "    Y_predict = model.predict(X_predict)\n",
    "        \n",
    "    return Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize predictions matrix\n",
    "STARTMONTH=121\n",
    "P = np.zeros(Y.shape)\n",
    "\n",
    "model = build_model([[32, 0.0001, 0.25],\n",
    "                     [32, 0.0001, 0.25],\n",
    "                     [1, 0.0001, 0.25],\n",
    "                    ])\n",
    "print(\"%s Start backtest training\" % (time.strftime(\"%H:%M:%S\")))\n",
    "\n",
    "count = 0\n",
    "for month_index in range(STARTMONTH, X.shape[0]+1):\n",
    "    predictions = fit_predict(model, X[:month_index, :], Y[:month_index])\n",
    "    predictions = [pred[0,0] for pred in predictions]\n",
    "    \n",
    "    try:\n",
    "        P[month_index]= predictions\n",
    "        sys.stdout.write('.')\n",
    "        count += 1\n",
    "        if count % 80 == 0:\n",
    "            print(\"\")\n",
    "            print(\"%s Still training\" % (time.strftime(\"%H:%M:%S\")))\n",
    "        sys.stdout.flush()\n",
    "    except IndexError:\n",
    "        # I want to run the fit and see the expected R-squared\n",
    "        # but we are storing the predictions in row of the month predicted\n",
    "        # so we have no row to store the last prediction (2017-01)\n",
    "        print(\"\\nlast prediction not stored\")\n",
    "\n",
    "print(\"%s End backtest training\" % (time.strftime(\"%H:%M:%S\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.zeros(P.shape[0])\n",
    "numstocks = 6 # top quintile (and bottom)\n",
    "\n",
    "for month_index in range(STARTMONTH, X.shape[0]):\n",
    "        # get indexes of sorted smallest to largest\n",
    "        select_array = np.argsort(P[month_index])\n",
    "        # leftmost 6\n",
    "        short_indexes = select_array[:numstocks]\n",
    "        # rightmost 6\n",
    "        long_indexes = select_array[-numstocks:]\n",
    "        # compute equal weighted long/short return\n",
    "        R[month_index] = np.mean(X[month_index, long_indexes])/2 - np.mean(X[month_index, short_indexes])/2\n",
    "\n",
    "results = R[STARTMONTH:]\n",
    "index = pd.date_range('01/01/1970',periods=564, freq='M')\n",
    "perfdata = pd.DataFrame(results,index=index,columns=['Returns'])\n",
    "perfdata['Equity'] = 100 * np.cumprod(1 + results / 100)\n",
    "\n",
    "stats = perfdata['Equity'].calc_stats()\n",
    "\n",
    "pd.DataFrame([stats.stats.loc['start'],\n",
    "              stats.stats.loc['end'],\n",
    "              stats.stats.loc['cagr'],\n",
    "              stats.stats.loc['yearly_vol'],\n",
    "              stats.stats.loc['yearly_sharpe'],\n",
    "              stats.stats.loc['max_drawdown'],\n",
    "              ffn.core.calc_sortino_ratio(perfdata.Returns, rf=0, nperiods=564, annualize=False),\n",
    "             ],\n",
    "            index = ['start',\n",
    "                     'end',\n",
    "                     'cagr',\n",
    "                     'yearly_vol',\n",
    "                     'yearly_sharpe',\n",
    "                     'max_drawdown',\n",
    "                     'sortino',\n",
    "                    ],\n",
    "            columns=['Value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perf = 100 * np.cumprod(1 + results / 100)\n",
    "\n",
    "x_coords = np.linspace(1970, 2016, perf.shape[0])\n",
    "\n",
    "trace1 = Scatter(\n",
    "    x = x_coords,\n",
    "    y = perf,\n",
    "    name = 'Growth of $1',    \n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        autorange=True\n",
    "    )\n",
    ")\n",
    "data = [trace1]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_frame = X[0]\n",
    "predictions = [z[0] for z in curr_frame]\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    predictions.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "    curr_frame = np.array(predictions[-window_size:]).reshape([window_size,1])    \n",
    "\n",
    "# truncate the ones which aren't predictions\n",
    "predictions = np.array(predictions[window_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_coords = np.linspace(0, 1, y.shape[0])\n",
    "\n",
    "trace1 = Scatter(\n",
    "    x = x_coords,\n",
    "    y = y,\n",
    "    name = 'Training data',    \n",
    ")\n",
    "trace2 = Scatter(    \n",
    "    x = x_coords,\n",
    "    y = predictions,\n",
    "    name = 'Predictions',\n",
    "\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "\n",
    "iplot(data, filename='basic-line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
